name: Test and Publish Nodes

on:
  push:
    branches:
      - main
  workflow_dispatch: # Allows manual trigger
  schedule:
    - cron: '0 */6 * * *' # Runs every 6 hours

concurrency:
  group: test-nodes
  cancel-in-progress: true

permissions:
  contents: write # Grant write permissions for pushing changes

jobs:
  test_nodes:
    runs-on: ubuntu-latest
    timeout-minutes: 60 # Set a timeout for the job (e.g., 60 minutes) to prevent infinite runs

    steps:
      - name: Checkout Code Repository
        uses: actions/checkout@v4

      - name: Set up Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Ensure Python 3.10 or higher for f-strings and type hints

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install httpx==0.27.2 aiodns==3.2.0 aiofiles==24.1.0 psutil==6.0.0

      - name: Initialize sub.txt (if not exists)
        # This step ensures data/sub.txt exists even if previous run failed to create it
        run: |
          mkdir -p data
          touch data/sub.txt
          # Add initial comment if file is empty or just created
          if ! grep -q "#" data/sub.txt; then
            echo "# Initial sub.txt" > data/sub.txt
          fi


      - name: Cache ss.txt # (Note: this cache is for the downloaded ss.txt content, not test results)
        # This cache might not be strictly necessary if ss.txt is small and fetched quickly.
        # It's more useful for build artifacts or large data.
        # For data/ss.txt, usually this refers to the input list, not the output.
        # You might consider caching history_results.json and dns_cache.json if they become very large
        # to speed up loading, but remember to invalidate appropriately.
        # For now, let's focus on the primary issue.
        uses: actions/cache@v4
        with:
          path: data/ss.txt
          key: ss-txt-${{ hashFiles('data/ss.txt') }} # Caches the raw ss.txt that's downloaded or exists.

      - name: Run Node Test Script
        run: |
          start_time=$(date +%s)
          python test_nodes.py
          end_time=$(date +%s)
          echo "Test script took $((end_time - start_time)) seconds"
        env:
          # PYTHONUNBUFFERED: "1" # Ensures output is unbuffered
          # DEBUG_LOG: "true" # Controls logging level in test_nodes.py. Use LOG_LEVEL instead.
          LOG_LEVEL: "INFO" # Set to INFO for general runs, DEBUG for debugging

      - name: Count Successful Nodes
        # Running the separate script to count successful nodes
        run: python count_successful_nodes.py

      - name: Commit and Push Updated Data Files
        if: success() # Only run if previous steps succeeded
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          # Ensure data files are present before adding
          git add data/sub.txt data/history_results.json data/dns_cache.json || true # Use '|| true' to prevent failure if file doesn't exist (though they should)
          git commit -m "Update test results and sub.txt [skip ci]" || echo "No changes to commit" # '|| echo' handles no changes
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.BOT }} # If you have a separate BOT token
         #GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Use the default GITHUB_TOKEN provided by Actions, which has enough permissions for 'contents: write'
