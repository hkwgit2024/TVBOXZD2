name: Download and Validate M3U8 URLs

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *' # 每天 UTC 0 点 0 分运行

jobs:
  download-and-validate:
    runs-on: ubuntu-latest
    timeout-minutes: 360 # 最长运行时间 6 小时

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: ${{ runner.os }}-pip-

    # 移除了 Selenium 相关的系统依赖安装，因为脚本中未使用
    # 如果您的 Python 脚本后续需要浏览器自动化，请再添加回来

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        # 如果启用ML，确保安装ML库，例如：
        # pip install sentence-transformers scikit-learn joblib fuzzywuzzy beautifulsoup4 pyyaml aiohttp tenacity
        # 建议requirements.txt中列出所有依赖

    - name: Cache data directory
      uses: actions/cache@v4
      with:
        path: data/
        # 确保缓存 key 包含 data 目录下的重要文件，例如 category_cache.json, classifier_model.pkl
        key: ${{ runner.os }}-data-${{ hashFiles('data/**') }}
        restore-keys: ${{ runner.os }}-data-

    - name: Run script
      env:
        BOT: ${{ secrets.BOT }}
        REPO_URL: ${{ secrets.REPO_URL }}
        USE_ML: 'false'  # 可设置为 'true' 启用 ML。请确保 data/classifier_model.pkl 存在
      run: |
        # 确保 data 目录存在，如果缓存没有恢复
        mkdir -p data/
        # 运行 Python 脚本并将所有输出重定向到文件
        time python download_m3u8.py 2>&1 | tee script_output.log

    - name: Upload logs
      if: always() # 总是上传日志，无论脚本是否成功
      uses: actions/upload-artifact@v4
      with:
        name: script-logs
        path: |
          script_output.log
          data/error_log.txt
          parser.log
        if-no-files-found: warn # 如果日志文件不存在，只发出警告而不是失败

    - name: Upload results
      if: always() # 总是上传结果，无论脚本是否成功
      uses: actions/upload-artifact@v4
      with:
        name: m3u8-results
        path: data/ # 上传整个 data 目录
        if-no-files-found: warn # 如果 data 目录为空，只发出警告

    - name: Commit and push results
      if: always() # 总是运行，即使前面步骤失败，确保尽力提交结果
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        
        # 添加 data 目录下的所有内容
        git add data/
        
        # 条件式添加 categories.yaml 文件，如果它存在的话
        if [ -f categories.yaml ]; then
          echo "Adding categories.yaml"
          git add categories.yaml
        else
          echo "categories.yaml does not exist in root, skipping git add."
        fi
        
        # 条件式添加 ML 模型文件，如果它存在的话 (现在假设在 data/ 目录下)
        if [ -f data/classifier_model.pkl ]; then
          echo "Adding data/classifier_model.pkl"
          git add data/classifier_model.pkl
        else
          echo "data/classifier_model.pkl does not exist, skipping git add."
        fi
        
        # 条件式添加训练数据文件，如果它存在的话 (现在假设在 data/ 目录下)
        if [ -f data/training_data.json ]; then
          echo "Adding data/training_data.json"
          git add data/training_data.json
        else
          echo "data/training_data.json does not exist, skipping git add."
        fi
        
        # 检查是否有实际的改动需要提交
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # 拉取最新代码并进行 rebase，避免推送到冲突
          git pull origin main --rebase
          # 提交更改，并使用 [skip ci] 避免无限循环触发
          git commit -m "Update M3U8 results and category cache [skip ci]"
          # 推送更改
          git push origin main
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # 使用 Actions 提供的默认 GITHUB_TOKEN

    - name: Notify on failure
      if: failure() # 仅当工作流失败时运行
      uses: actions/github-script@v7
      with:
        script: |
          const { owner, repo } = context.repo;
          const runId = context.runId;
          await github.rest.issues.create({
            owner,
            repo,
            title: `Workflow Failure: Run ${runId}`,
            body: `Workflow failed for run ${runId}. Check logs: https://github.com/${owner}/${repo}/actions/runs/${runId}`
          });
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Notify on success
      if: success() # 仅当工作流成功时运行
      run: |
        # 从日志中获取有效 URL 数量
        VALID_COUNT=$(grep -c "Valid URL" script_output.log || echo 0)
        echo "Workflow succeeded with $VALID_COUNT valid URLs"
