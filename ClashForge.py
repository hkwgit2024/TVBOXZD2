# -*- coding: utf-8 -*-
# !/usr/bin/env python3
import base64
import subprocess
import threading
import time
import urllib.parse
import json
import glob
import re
import yaml
import random
import string
import httpx
import asyncio
from itertools import chain
from typing import Dict, List, Optional
import sys
import requests
import platform
import os
from datetime import datetime
from asyncio import Semaphore
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
import warnings
warnings.filterwarnings('ignore')
from requests_html import HTMLSession
import psutil
import logging
from tqdm import tqdm
import socket
import gzip

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# æ·»åŠ æ–°å‡½æ•°ï¼šç§»é™¤ YAML ä¸­ä¸å…è®¸çš„æ§åˆ¶å­—ç¬¦
def remove_invalid_yaml_chars(text):
    """ç§»é™¤ YAML ä¸­ä¸å…è®¸çš„æ§åˆ¶å­—ç¬¦"""
    if not isinstance(text, str):
        return text
    # ç§»é™¤é™¤åˆ¶è¡¨ç¬¦(\t), æ¢è¡Œç¬¦(\n), å›è½¦ç¬¦(\r) ä¹‹å¤–çš„æ‰€æœ‰ ASCII æ§åˆ¶å­—ç¬¦
    cleaned_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)
    return cleaned_text

TEST_URL = "http://www.pinterest.com"
CLASH_API_PORTS = [9090]
CLASH_API_HOSTS = ['127.0.0.1', 'localhost']
TIMEOUT = 3
CLASH_PATH_DIR = 'mihomo'
CLASH_GZ_PATH = os.path.join(CLASH_PATH_DIR, 'mihomo-linux-amd64-compatible-v1.19.13.gz')
CLASH_EXEC_NAME = 'mihomo-linux-amd64-compatible-v1.19.13'
CLASH_EXEC_PATH = os.path.join(CLASH_PATH_DIR, CLASH_EXEC_NAME)
INPUT = 'links'
OUTPUT = 'configs'
NODE_OUTPUT_LIMIT = 386
MAX_CONCURRENT_TESTS = 30
NODE_REJECT_TYPES = ['trojan-go']
SOURCE_LINK = "https://raw.githubusercontent.com/qjlxg/HA/main/link.yaml"

# æ£€æŸ¥å¹¶è§£å‹ mihomo å¯æ‰§è¡Œæ–‡ä»¶
def ensure_clash_executable():
    """ç¡®ä¿ Clash å¯æ‰§è¡Œæ–‡ä»¶å­˜åœ¨ä¸”å¯æ‰§è¡Œ"""
    if not os.path.exists(CLASH_EXEC_PATH):
        if os.path.exists(CLASH_GZ_PATH):
            logger.info(f"å‘ç°å‹ç¼©åŒ… {CLASH_GZ_PATH}, æ­£åœ¨è§£å‹...")
            try:
                with gzip.open(CLASH_GZ_PATH, 'rb') as f_in, open(CLASH_EXEC_PATH, 'wb') as f_out:
                    f_out.write(f_in.read())
                os.chmod(CLASH_EXEC_PATH, 0o755) # æ·»åŠ å¯æ‰§è¡Œæƒé™
                logger.info(f"è§£å‹å®Œæˆï¼Œæ–‡ä»¶å·²ä¿å­˜åˆ° {CLASH_EXEC_PATH}")
                return True
            except Exception as e:
                logger.error(f"è§£å‹æ–‡ä»¶å¤±è´¥: {e}")
                return False
        else:
            logger.error(f"Clash å¯æ‰§è¡Œæ–‡ä»¶æˆ–å‹ç¼©åŒ…å‡ä¸å­˜åœ¨: {CLASH_EXEC_PATH} æˆ– {CLASH_GZ_PATH}")
            return False
    else:
        logger.info(f"Clash å¯æ‰§è¡Œæ–‡ä»¶å·²å­˜åœ¨: {CLASH_EXEC_PATH}")
        return True

# è·å–clashçš„apiç«¯å£
def get_clash_api_port():
    for port in CLASH_API_PORTS:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex(('127.0.0.1', port)) == 0:
                return port
    return None

# è·å–ä¸€ä¸ªå¯ç”¨çš„clash api
def get_clash_api():
    port = get_clash_api_port()
    if port:
        return f"http://127.0.0.1:{port}"
    return None

def switch_proxy(group_name, proxy_name):
    """åˆ‡æ¢Clashé…ç½®ä¸­çš„ä»£ç†èŠ‚ç‚¹"""
    api_url = get_clash_api()
    if not api_url:
        logger.error("æ— æ³•æ‰¾åˆ° Clash API ç«¯å£ã€‚")
        return False
    url = f"{api_url}/proxies/{group_name}"
    headers = {'Content-Type': 'application/json'}
    payload = {'name': proxy_name}
    try:
        response = requests.put(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"åˆ‡æ¢ä»£ç†å¤±è´¥: {e}")
        return False

async def test_proxy(client, proxy_name, url, semaphore):
    """å¼‚æ­¥æµ‹è¯•å•ä¸ªä»£ç†èŠ‚ç‚¹ï¼Œå¹¶è¿”å›å»¶è¿Ÿ"""
    start_time = time.time()
    try:
        async with semaphore:
            # ä»£ç†é€šè¿‡ 7890 ç«¯å£ï¼Œç”± Clash å¤„ç†
            async with client.stream('GET', url, proxies={'http://': 'http://127.0.0.1:7890', 'https://': 'http://127.0.0.1:7890'}, timeout=TIMEOUT) as response:
                await response.aread()
                end_time = time.time()
                delay = int((end_time - start_time) * 1000)
                return proxy_name, delay
    except (httpx.RequestError, asyncio.TimeoutError) as e:
        return proxy_name, -1
    except Exception as e:
        logger.error(f"æµ‹è¯•ä»£ç† {proxy_name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return proxy_name, -1

async def proxy_clean():
    """å¼‚æ­¥æµ‹é€Ÿå’Œè¿‡æ»¤"""
    proxies = get_nodes_from_clash_api()
    if not proxies:
        logger.error("æœªèƒ½ä» Clash API è·å–åˆ°ä»£ç†åˆ—è¡¨ï¼Œæ— æ³•è¿›è¡Œæµ‹é€Ÿã€‚")
        return {}

    logger.info(f"å¼€å§‹æ‰¹é‡æ£€æµ‹ {len(proxies)} ä¸ªä»£ç†å»¶è¿Ÿ...")
    
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TESTS)
    delays = {}
    async with httpx.AsyncClient(verify=False) as client:
        # ä½¿ç”¨ tqdm åŒ…è£…ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡
        tasks = [test_proxy(client, proxy, TEST_URL, semaphore) for proxy in proxies]
        results = await asyncio.gather(*tasks)
        
        for proxy, delay in tqdm(results, desc="ä»£ç†æµ‹é€Ÿè¿›åº¦"):
            delays[proxy] = delay
    
    logger.info("æ‰¹é‡æ£€æµ‹å®Œæ¯•ã€‚")
    return delays

def start_clash(config_path=os.path.join(OUTPUT, 'config.yaml')):
    """å¯åŠ¨ Clash å¹¶è¿”å›è¿›ç¨‹å¯¹è±¡"""
    if not os.path.exists(config_path):
        logger.error("Clash é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•å¯åŠ¨ã€‚")
        return None
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ Clash è¿›ç¨‹å¹¶ç»ˆæ­¢å®ƒä»¬
    for proc in psutil.process_iter(['name']):
        if proc.name() in [CLASH_EXEC_NAME]:
            logger.info(f"å‘ç°æ­£åœ¨è¿è¡Œçš„ Clash è¿›ç¨‹: {proc.name()}, æ­£åœ¨ç»ˆæ­¢...")
            try:
                proc.kill()
            except psutil.NoSuchProcess:
                pass
            time.sleep(1) # ç­‰å¾…è¿›ç¨‹å®Œå…¨å…³é—­

    # ä¿®æ­£é…ç½®æ–‡ä»¶è·¯å¾„ä¸ºç›¸å¯¹ mihomo ç›®å½•çš„è·¯å¾„
    rel_config_path = os.path.relpath(config_path, CLASH_PATH_DIR)

    # ä¿®æ­£åçš„å‘½ä»¤ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„çš„å¯æ‰§è¡Œæ–‡ä»¶å
    clash_cmd = [CLASH_EXEC_NAME, '-f', rel_config_path]
    
    # æ£€æŸ¥ Clash å¯æ‰§è¡Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CLASH_EXEC_PATH):
        logger.error(f"Clash å¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {CLASH_EXEC_PATH}")
        return None
    
    # å¢åŠ æ—¥å¿—
    logger.info(f"æ­£åœ¨å¯åŠ¨ Clash è¿›ç¨‹ï¼Œå‘½ä»¤: {' '.join(clash_cmd)}")
    
    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹æ‰§è¡Œ
    clash_process = subprocess.Popen(clash_cmd, cwd=CLASH_PATH_DIR, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    
    # ç­‰å¾… Clash API å¯åŠ¨
    start_time = time.time()
    while time.time() - start_time < 10:
        if get_clash_api_port():
            logger.info("Clash API å·²æˆåŠŸå¯åŠ¨ã€‚")
            return clash_process
        time.sleep(1)
    
    logger.error("Clash API å¯åŠ¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æˆ– Clash å¯æ‰§è¡Œæ–‡ä»¶ã€‚")
    clash_process.kill()
    return None

def merge_lists(*args):
    """åˆå¹¶å¤šä¸ªåˆ—è¡¨å¹¶å»é‡"""
    return list(set(chain.from_iterable(arg for arg in args if isinstance(arg, list))))

def get_nodes_from_clash_api():
    """ä» Clash API è·å–æ‰€æœ‰ä»£ç†èŠ‚ç‚¹"""
    api_url = get_clash_api()
    if not api_url:
        logger.error("æ— æ³•æ‰¾åˆ° Clash API ç«¯å£ã€‚")
        return []
    url = f"{api_url}/proxies"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        proxies_data = response.json().get('proxies', {})
        proxies = [name for name, details in proxies_data.items() if details.get('type') not in ['Direct', 'Fallback', 'Selector', 'URLTest', 'load-balance']]
        return proxies
    except requests.exceptions.RequestException as e:
        logger.error(f"è·å– Clash ä»£ç†åˆ—è¡¨å¤±è´¥: {e}")
        return []

def filter_by_types_alt(allowed_types, nodes):
    """è¿‡æ»¤èŠ‚ç‚¹"""
    return [node for node in nodes if node.get('type') in allowed_types]

def process_subscribe_link(link):
    """å¤„ç†è®¢é˜…é“¾æ¥ï¼Œè¿”å›èŠ‚ç‚¹åˆ—è¡¨"""
    try:
        logger.info(f"æ­£åœ¨è·å–è®¢é˜…é“¾æ¥: {link}")
        session = HTMLSession()
        r = session.get(link, timeout=10)
        if r.status_code != 200:
            logger.error(f"è·å–é“¾æ¥å¤±è´¥: {link}, çŠ¶æ€ç : {r.status_code}")
            return []
        
        content = r.text
        
        try:
            decoded_content = base64.b64decode(content).decode('utf-8')
        except:
            decoded_content = content
        
        if link.endswith('clash') or ('&clash=3' in link):
            try:
                config = yaml.safe_load(decoded_content)
                if isinstance(config, dict) and 'proxies' in config:
                    return config['proxies']
            except yaml.YAMLError as e:
                logger.error(f"è§£æ YAML å¤±è´¥: {e}")
                return []
        
        # å¤„ç† vmess, ss ç­‰
        lines = decoded_content.strip().split('\n')
        nodes = []
        for line in lines:
            if line.startswith(('vmess://', 'ss://')):
                nodes.append({'name': 'proxy_' + ''.join(random.choices(string.ascii_letters + string.digits, k=8)), 'type': 'ss' if line.startswith('ss://') else 'vmess'})
            # ... å…¶ä»–åè®®è§£æé€»è¾‘
        
        return nodes
    except Exception as e:
        logger.error(f"å¤„ç†è®¢é˜…é“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

def read_txt_files(folder_path):
    """ä»æŒ‡å®šæ–‡ä»¶å¤¹è¯»å– txt æ–‡ä»¶å¹¶è¿”å›é“¾æ¥åˆ—è¡¨"""
    all_links = []
    if not os.path.exists(folder_path):
        logger.warning(f"æ–‡ä»¶å¤¹ '{folder_path}' ä¸å­˜åœ¨ã€‚")
        return []

    for file_name in glob.glob(os.path.join(folder_path, '*.txt')):
        try:
            with open(file_name, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                links = [line.strip() for line in lines if line.strip()]
                all_links.extend(links)
                logger.info(f"ä»æ–‡ä»¶ '{file_name}' è¯»å–äº† {len(links)} ä¸ªé“¾æ¥ã€‚")
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶ '{file_name}' å¤±è´¥: {e}")

    return all_links

def read_yaml_files(folder_path):
    """ä»æŒ‡å®šæ–‡ä»¶å¤¹è¯»å– YAML æ–‡ä»¶å¹¶è¿”å›èŠ‚ç‚¹åˆ—è¡¨"""
    all_nodes = []
    if not os.path.exists(folder_path):
        logger.warning(f"æ–‡ä»¶å¤¹ '{folder_path}' ä¸å­˜åœ¨ã€‚")
        return []

    for file_name in glob.glob(os.path.join(folder_path, '*.yaml')):
        try:
            with open(file_name, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                if isinstance(config, dict) and 'proxies' in config:
                    all_nodes.extend(config['proxies'])
                    logger.info(f"ä»æ–‡ä»¶ '{file_name}' è¯»å–äº† {len(config['proxies'])} ä¸ªèŠ‚ç‚¹ã€‚")
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶ '{file_name}' å¤±è´¥: {e}")

    return all_nodes

def generate_clash_config(nodes_to_write, output_path=os.path.join(OUTPUT, 'config.yaml')):
    """ç”Ÿæˆ Clash é…ç½®æ–‡ä»¶"""
    
    # æ£€æŸ¥èŠ‚ç‚¹åç§°æ˜¯å¦é‡å¤å¹¶æ·»åŠ åç¼€
    node_names = set()
    all_nodes_cleaned = []
    for node in nodes_to_write:
        original_name = node.get('name')
        if not original_name:
            continue
        new_name = original_name
        count = 1
        while new_name in node_names:
            new_name = f"{original_name}-{count}"
            count += 1
        node['name'] = new_name
        node_names.add(new_name)
        all_nodes_cleaned.append(node)

    config_template = {
        'port': 7890,
        'socks-port': 7891,
        'allow-lan': True,
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'external-ui': 'ui',
        'secret': '',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fallback-filter': {
                'geoip': True,
                'geosite': False
            },
            'nameserver': [
                '114.114.114.114',
                '8.8.4.4',
                '223.5.5.5',
                '8.8.8.8'
            ]
        },
        'proxies': all_nodes_cleaned,
        'proxy-groups': [
            {
                'name': 'èŠ‚ç‚¹é€‰æ‹©',
                'type': 'select',
                'proxies': ['è‡ªåŠ¨é€‰æ‹©'] + [n['name'] for n in all_nodes_cleaned]
            },
            {
                'name': 'è‡ªåŠ¨é€‰æ‹©',
                'type': 'url-test',
                'url': TEST_URL,
                'interval': 300,
                'tolerance': 50,
                'proxies': [n['name'] for n in all_nodes_cleaned]
            },
            {
                'name': 'ğŸ”°å›½å¤–æµé‡',
                'type': 'select',
                'proxies': ['è‡ªåŠ¨é€‰æ‹©', 'DIRECT']
            },
            {
                'name': 'ğŸƒå›½å†…æµé‡',
                'type': 'select',
                'proxies': ['DIRECT']
            },
            {
                'name': 'ğŸš€GPT',
                'type': 'select',
                'proxies': ['ğŸ”°å›½å¤–æµé‡', 'è‡ªåŠ¨é€‰æ‹©']
            },
            {
                'name': 'ğŸè‹¹æœæœåŠ¡',
                'type': 'select',
                'proxies': ['ğŸ”°å›½å¤–æµé‡', 'DIRECT', 'è‡ªåŠ¨é€‰æ‹©']
            },
            {
                'name': 'ğŸŒæ¼ç½‘ä¹‹é±¼',
                'type': 'select',
                'proxies': ['ğŸ”°å›½å¤–æµé‡', 'è‡ªåŠ¨é€‰æ‹©', 'DIRECT']
            },
            {
                'name': 'ğŸ›‘å¹¿å‘Šæ‹¦æˆª',
                'type': 'select',
                'proxies': ['REJECT', 'DIRECT']
            }
        ],
        'rules': [
            'DOMAIN-KEYWORD,apple,ğŸè‹¹æœæœåŠ¡',
            'DOMAIN-SUFFIX,openai.com,ğŸš€GPT',
            'GEOSITE,CN,ğŸƒå›½å†…æµé‡',
            'GEOIP,CN,ğŸƒå›½å†…æµé‡',
            'MATCH,ğŸŒæ¼ç½‘ä¹‹é±¼'
        ]
    }
    
    # å°†åˆ—è¡¨è½¬æ¢ä¸ºé›†åˆä»¥å¿«é€ŸæŸ¥æ‰¾ï¼Œå¹¶ç§»é™¤ä¸å­˜åœ¨çš„ä»£ç†ç»„
    proxy_groups = config_template['proxy-groups']
    proxy_names = {node['name'] for node in all_nodes_cleaned}
    
    for group in proxy_groups:
        if 'proxies' in group:
            valid_proxies = []
            for proxy in group['proxies']:
                if proxy in ['è‡ªåŠ¨é€‰æ‹©', 'DIRECT', 'REJECT', 'ğŸ”°å›½å¤–æµé‡', 'ğŸƒå›½å†…æµé‡', 'ğŸš€GPT', 'ğŸè‹¹æœæœåŠ¡', 'ğŸŒæ¼ç½‘ä¹‹é±¼', 'ğŸ›‘å¹¿å‘Šæ‹¦æˆª']:
                    valid_proxies.append(proxy)
                elif proxy in proxy_names:
                    valid_proxies.append(proxy)
                else:
                    logger.warning(f"ä»£ç†ç»„ '{group['name']}' ä¸­å¼•ç”¨çš„ä»£ç† '{proxy}' ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
            group['proxies'] = valid_proxies

    # å°†é…ç½®æ–‡ä»¶å†™å…¥æ–‡ä»¶
    if not os.path.exists(OUTPUT):
        os.makedirs(OUTPUT)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        yaml.dump(config_template, f, allow_unicode=True, sort_keys=False)
    
    logger.info(f"Clash é…ç½®æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆ: {output_path}")

def main(links, check, allowed_types, only_check):
    """ä¸»ç¨‹åº"""
    clash_process = None
    try:
        # Step 0: ç¡®ä¿ Clash å¯æ‰§è¡Œæ–‡ä»¶å­˜åœ¨
        if not ensure_clash_executable():
            return
            
        # Step 1: ä»æ­£ç¡®çš„æ¥æºè·å–æ‰€æœ‰èŠ‚ç‚¹
        logger.info(f"æ­£åœ¨ä» {SOURCE_LINK} è·å–èŠ‚ç‚¹...")
        try:
            response = requests.get(SOURCE_LINK, timeout=15)
            response.raise_for_status()
            config = yaml.safe_load(response.text)
            source_nodes = config.get('proxies', [])
        except Exception as e:
            logger.error(f"æ— æ³•ä»æ¥æºé“¾æ¥è·å–æˆ–è§£æèŠ‚ç‚¹: {e}")
            source_nodes = []

        all_nodes = source_nodes
        logger.info(f"ä»æ¥æºé“¾æ¥æ€»å…±è·å–äº† {len(all_nodes)} ä¸ªèŠ‚ç‚¹ã€‚")
        
        # è¿‡æ»¤æ‰ä¸æ”¯æŒçš„èŠ‚ç‚¹ç±»å‹
        all_nodes = [node for node in all_nodes if node.get('type') not in NODE_REJECT_TYPES]
        logger.info(f"è¿‡æ»¤åå‰©ä½™ {len(all_nodes)} ä¸ªå¯ç”¨èŠ‚ç‚¹ã€‚")

        # ä¼˜åŒ–ï¼šé™åˆ¶æµ‹è¯•çš„èŠ‚ç‚¹æ•°é‡
        nodes_to_test = all_nodes
        if len(nodes_to_test) > NODE_OUTPUT_LIMIT:
            logger.warning(f"èŠ‚ç‚¹æ•°é‡ ({len(nodes_to_test)}) è¶…è¿‡äº†é™åˆ¶ ({NODE_OUTPUT_LIMIT})ï¼Œå°†åªæµ‹è¯•å‰ {NODE_OUTPUT_LIMIT} ä¸ªèŠ‚ç‚¹ã€‚")
            nodes_to_test = nodes_to_test[:NODE_OUTPUT_LIMIT]
        
        # Step 2: ç”Ÿæˆ Clash é…ç½®æ–‡ä»¶
        generate_clash_config(nodes_to_test)
        
        # Step 3: å¯åŠ¨ Clash å¹¶è¿›è¡Œæµ‹é€Ÿ
        if check or only_check:
            print(f"===================å¯åŠ¨ Clash å¹¶åˆå§‹åŒ–é…ç½®======================")
            clash_process = start_clash()
            if clash_process is None:
                return
            
            # ç­‰å¾…Clashå¯åŠ¨å¹¶åˆ‡æ¢åˆ°è‡ªåŠ¨é€‰æ‹©
            time.sleep(5)
            switch_proxy('èŠ‚ç‚¹é€‰æ‹©', 'è‡ªåŠ¨é€‰æ‹©')
            
            # è¿è¡Œæµ‹é€Ÿ
            delays = asyncio.run(proxy_clean())
            
            # Step 4: æ ¹æ®æµ‹é€Ÿç»“æœè¿‡æ»¤å’Œæ’åºèŠ‚ç‚¹
            good_proxies = sorted([p for p, d in delays.items() if d > 0], key=lambda p: delays[p])
            
            logger.info(f"æµ‹é€Ÿå®Œæˆï¼Œæ‰¾åˆ° {len(good_proxies)} ä¸ªå¯ç”¨èŠ‚ç‚¹ã€‚")
            
            if not good_proxies:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨èŠ‚ç‚¹ã€‚")
            else:
                final_nodes = [node for name in good_proxies for node in all_nodes if node.get('name') == name]
                
                # é‡æ–°ç”Ÿæˆæœ€ç»ˆçš„é…ç½®æ–‡ä»¶
                generate_clash_config(final_nodes, output_path=os.path.join(OUTPUT, 'clash.yaml'))
                logger.info(f"å·²ç”ŸæˆåŒ…å« {len(final_nodes)} ä¸ªå¯ç”¨èŠ‚ç‚¹çš„æ–°é…ç½®æ–‡ä»¶: {os.path.join(OUTPUT, 'clash.yaml')}")

    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        logger.info("å…³é—­ Clash è¿›ç¨‹")
        if clash_process is not None:
            clash_process.kill()
            logger.info("Clash è¿›ç¨‹å·²ç»ˆæ­¢")

if __name__ == '__main__':
    main(links=[], check=True, allowed_types=['vmess', 'ss', 'trojan', 'ss-libev', 'v2ray'], only_check=False)
