import aiohttp
import asyncio
import yaml
import os
import subprocess
import time
import argparse
import base64
import json
from urllib.parse import urlparse, parse_qs, unquote
import logging
import psutil
import tempfile
import socket
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set
import aiofiles
import re # Added import for re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_invalid_nodes(file_path: str) -> List[Dict]:
    """
    åŠ è½½ä¸Šæ¬¡çš„ä¸å¯ç”¨èŠ‚ç‚¹ã€‚
    è¿‡æ»¤æ‰ä»»ä½•éå­—å…¸ç±»å‹çš„æ¡ç›®ï¼Œä»¥ç¡®ä¿æ•°æ®çš„æœ‰æ•ˆæ€§ã€‚
    """
    if not os.path.exists(file_path):
        return []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            nodes = yaml.safe_load(f) or []
        # è¿‡æ»¤æ‰ä»»ä½•å¯èƒ½å·²è¢«åŠ è½½çš„éå­—å…¸æ¡ç›®ï¼Œè¿™æ˜¯ä¸€ç§é˜²å¾¡æ€§æ£€æŸ¥
        filtered_nodes = [node for node in nodes if isinstance(node, dict)]
        return filtered_nodes
    except Exception as e:
        logger.error(f"åŠ è½½ä¸å¯ç”¨èŠ‚ç‚¹æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
        return []

async def save_nodes(file_path: str, nodes: List[Dict]):
    """å¼‚æ­¥ä¿å­˜èŠ‚ç‚¹åˆ°æ–‡ä»¶"""
    async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:
        await f.write(yaml.dump(nodes, allow_unicode=True))

def get_node_key(proxy: Dict) -> str:
    """
    ç”ŸæˆèŠ‚ç‚¹å”¯ä¸€æ ‡è¯†ã€‚
    å¢åŠ å¥å£®æ€§æ£€æŸ¥ï¼Œç¡®ä¿ proxy æ˜¯å­—å…¸ä¸”åŒ…å«æ‰€æœ‰å¿…è¦é”®ã€‚
    """
    if not isinstance(proxy, dict):
        logger.warning(f"get_node_key æ”¶åˆ°éå­—å…¸ç±»å‹: {proxy}. è·³è¿‡ç”Ÿæˆé”®ã€‚")
        return "" # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ— æ³•ç”Ÿæˆæœ‰æ•ˆé”®
    required_keys = ['server', 'port', 'name']
    if not all(key in proxy for key in required_keys):
        logger.warning(f"ä»£ç†ç¼ºå°‘ç”ŸæˆèŠ‚ç‚¹é”®æ‰€éœ€çš„ä¿¡æ¯: {proxy}. è·³è¿‡ç”Ÿæˆé”®ã€‚")
        return "" # å¦‚æœç¼ºå°‘å¿…è¦é”®ï¼Œä¹Ÿè¿”å›ç©ºå­—ç¬¦ä¸²
    return f"{proxy['server']}:{proxy['port']}:{proxy['name']}"

async def fetch_proxies(url: str) -> List[Dict]:
    """ä»è¿œç¨‹ URL ä¸‹è½½å¹¶è§£æä»£ç†èŠ‚ç‚¹"""
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url, timeout=30) as response:
                if response.status != 200:
                    logger.error(f"æ— æ³•ä» {url} è·å–ä»£ç†èŠ‚ç‚¹: HTTP {response.status}")
                    return []
                content = await response.text()
                # ç«‹å³è¿‡æ»¤æ‰ parse_proxy_line è¿”å›çš„ None ç»“æœ
                proxies = [proxy for line in content.splitlines() if (proxy := parse_proxy_line(line.strip())) is not None]
                logger.info(f"ä» {url} åŠ è½½äº† {len(proxies)} ä¸ªä»£ç†èŠ‚ç‚¹")
                return proxies
        except Exception as e:
            logger.error(f"è·å–ä»£ç†èŠ‚ç‚¹å¤±è´¥: {e}")
            return []

def parse_proxy_line(line: str) -> Optional[Dict]:
    """è§£æå•è¡Œä»£ç† URIï¼Œæ”¯æŒ Trojan, SS, Vmess, Hysteria2"""
    try:
        parts = line.split('#', 1)
        uri = parts[0]
        name = unquote(parts[1]) if len(parts) > 1 else f"æœªçŸ¥èŠ‚ç‚¹_{time.time()}"
        url_parts = urlparse(uri)
        scheme = url_parts.scheme.lower()
        proxy = {'name': name, 'tested_at': datetime.now().isoformat()}  # æ·»åŠ æ—¶é—´æˆ³

        if scheme == 'trojan':
            auth_data = url_parts.netloc.split('@')
            if len(auth_data) != 2:
                logger.warning(f"è§£æ Trojan èŠ‚ç‚¹å¤±è´¥ï¼Œæ ¼å¼é”™è¯¯: {uri}")
                return None
            proxy['type'] = 'trojan'
            proxy['password'] = auth_data[0]
            server_port = auth_data[1]
            if ipv6_match := re.match(r'\[(.*?)\]:(\d+)', server_port):
                proxy['server'], proxy['port'] = ipv6_match.group(1), int(ipv6_match.group(2))
            else:
                host, port_str = server_port.split(':')
                proxy['server'] = host
                proxy['port'] = int(port_str)
            params = parse_qs(url_parts.query)
            proxy['sni'] = params.get('sni', [''])[0]
            # Trojan ä½¿ç”¨ allowInsecure å‚æ•°
            proxy['skip-cert-verify'] = params.get('allowInsecure', ['0'])[0] == '1'
            proxy['network'] = params.get('type', ['tcp'])[0]
            proxy['path'] = params.get('path', [''])[0]
            proxy['host'] = params.get('host', [''])[0]
            return proxy
        elif scheme == 'ss':
            try:
                # Shadowsocks URI æ ¼å¼é€šå¸¸ä¸º base64(method:password@server:port)
                # æˆ–è€…ç›´æ¥æ˜¯ ss://method:password@server:port#name
                # è¿™é‡Œå‡è®¾æ˜¯ base64(method:password@server:port)
                decoded_uri = base64.b64decode(url_parts.netloc).decode('utf-8')
                parts = decoded_uri.split('@')
                if len(parts) != 2: raise ValueError("æ— æ•ˆçš„ Shadowsocks URI æ ¼å¼")
                method_passwd = parts[0].split(':', 1)
                server_port = parts[1].split(':', 1)

                proxy['type'] = 'ss'
                proxy['cipher'] = method_passwd[0]
                proxy['password'] = method_passwd[1]
                proxy['server'] = server_port[0]
                proxy['port'] = int(server_port[1])
                return proxy
            except Exception as ss_e:
                logger.warning(f"è§£æ Shadowsocks èŠ‚ç‚¹å¤±è´¥ {uri}: {ss_e}")
                return None
        elif scheme == 'vmess':
            # VMESS URI é€šå¸¸æ˜¯ base64 ç¼–ç çš„ JSON å­—ç¬¦ä¸²
            try:
                decoded_vmess = base64.b64decode(url_parts.netloc).decode('utf-8')
                vmess_data = json.loads(decoded_vmess)
                proxy['type'] = 'vmess'
                proxy['server'] = vmess_data.get('add')
                proxy['port'] = int(vmess_data.get('port'))
                proxy['uuid'] = vmess_data.get('id')
                proxy['alterId'] = vmess_data.get('aid', 0)
                proxy['cipher'] = vmess_data.get('scy', 'auto') # security
                proxy['network'] = vmess_data.get('net', 'tcp')
                proxy['tls'] = vmess_data.get('tls', '') == 'tls'
                proxy['ws-path'] = vmess_data.get('path', '')
                proxy['ws-headers'] = {'Host': vmess_data.get('host', '')} if vmess_data.get('host') else {}
                return proxy
            except Exception as vmess_e:
                logger.warning(f"è§£æ Vmess èŠ‚ç‚¹å¤±è´¥ {uri}: {vmess_e}")
                return None
        elif scheme == 'hy2' or scheme == 'hysteria2':
            # Hysteria2 URI æ ¼å¼: hy2://password@server:port?sni=example.com&obfs=none&obfs-password=
            try:
                password_server_port = url_parts.netloc
                parts = password_server_port.split('@', 1)
                password = parts[0]
                server_port_str = parts[1] if len(parts) > 1 else ''

                if not server_port_str:
                    logger.warning(f"è§£æ Hysteria2 èŠ‚ç‚¹å¤±è´¥ï¼Œç¼ºå°‘æœåŠ¡å™¨å’Œç«¯å£ä¿¡æ¯: {uri}")
                    return None

                if ipv6_match := re.match(r'\[(.*?)\]:(\d+)', server_port_str):
                    server, port = ipv6_match.group(1), int(ipv6_match.group(2))
                else:
                    server, port_str = server_port_str.split(':')
                    port = int(port_str)

                params = parse_qs(url_parts.query)

                proxy['type'] = 'hysteria2'
                proxy['password'] = password
                proxy['server'] = server
                proxy['port'] = port
                proxy['obfs'] = params.get('obfs', ['none'])[0]
                proxy['obfs-password'] = params.get('obfs-password', [''])[0]
                proxy['sni'] = params.get('sni', [''])[0]
                # Hysteria2 ä½¿ç”¨ 'insecure' å‚æ•°è€Œä¸æ˜¯ 'allowInsecure'
                proxy['skip-cert-verify'] = params.get('insecure', ['0'])[0] == '1' 
                return proxy
            except Exception as hy2_e:
                logger.warning(f"è§£æ Hysteria2 èŠ‚ç‚¹å¤±è´¥ {uri}: {hy2_e}")
                return None
        else:
            logger.warning(f"ä¸æ”¯æŒçš„åè®®: {scheme}. URI: {uri}")
            return None
    except Exception as e:
        logger.warning(f"è§£æä»£ç†è¡Œå¤±è´¥ {line}: {e}")
        return None

def get_free_port() -> int:
    """è·å–ç©ºé—²ç«¯å£"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind(('localhost', 0))
        return s.getsockname()[1]

async def test_proxy(proxy: Dict, session: aiohttp.ClientSession, clash_bin: str, clash_port: int) -> Dict:
    """
    æµ‹è¯•å•ä¸ªä»£ç†èŠ‚ç‚¹ã€‚
    åˆ›å»º Clash é…ç½®æ–‡ä»¶å¹¶å¯åŠ¨ Clash è¿›ç¨‹ï¼Œç„¶åé€šè¿‡ Clash æµ‹è¯•ä»£ç†ã€‚
    """
    result = {'proxy': proxy, 'status': 'ä¸å¯ç”¨', 'latency': 0, 'error': ''}
    
    # ç¡®ä¿ä»£ç†å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®æ¥æ„å»º Clash é…ç½®
    required_clash_keys = ['name', 'type', 'server', 'port']
    if not all(key in proxy for key in required_clash_keys):
        result['error'] = "ä»£ç†é…ç½®ç¼ºå°‘å¿…è¦ä¿¡æ¯ (name, type, server, port)ã€‚"
        logger.error(f"ä»£ç†é…ç½®ç¼ºå°‘å¿…è¦ä¿¡æ¯: {proxy}")
        return result

    config = {
        'port': clash_port,
        'socks-port': clash_port + 1,
        'external-controller': f'127.0.0.1:{clash_port + 2}',
        'allow-lan': False,
        'mode': 'rule',
        'log-level': 'error',
        'proxies': [proxy],
        'proxy-groups': [{'name': 'auto', 'type': 'select', 'proxies': [proxy['name']]}],
        'rules': ['MATCH,auto']
    }
    
    config_path = None
    proc = None
    try:
        with tempfile.NamedTemporaryFile('w', suffix='.yaml', delete=False, encoding='utf-8') as f:
            config_path = f.name
            yaml.dump(config, f, allow_unicode=True)

        # å¯åŠ¨ Clash è¿›ç¨‹
        # stderr=subprocess.PIPE å…è®¸æˆ‘ä»¬æ•è· Clash çš„é”™è¯¯è¾“å‡º
        proc = subprocess.Popen([clash_bin, '-f', config_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        await asyncio.sleep(2) # ç»™äºˆ Clash å¯åŠ¨æ—¶é—´

        # æ£€æŸ¥ Clash è¿›ç¨‹æ˜¯å¦å·²é€€å‡ºï¼ˆå¯åŠ¨å¤±è´¥ï¼‰
        if proc.poll() is not None:
            stdout, stderr = proc.communicate(timeout=1) # å°è¯•è¯»å–å‰©ä½™è¾“å‡º
            result['error'] = (f"Clash å¯åŠ¨å¤±è´¥. é€€å‡ºç : {proc.returncode}, "
                               f"æ ‡å‡†è¾“å‡º: {stdout.decode(errors='ignore').strip()}, "
                               f"æ ‡å‡†é”™è¯¯: {stderr.decode(errors='ignore').strip()}")
            logger.error(result['error'])
            return result

        try:
            start_time = time.time()
            async with session.get(
                'http://www.cloudflare.com',  # ä½¿ç”¨ Cloudflare ä½œä¸ºæµ‹è¯•ç›®æ ‡
                proxy=f'http://127.0.0.1:{clash_port}',
                timeout=10
            ) as response:
                if response.status == 200:
                    result['status'] = 'å¯ç”¨'
                    result['latency'] = (time.time() - start_time) * 1000
                else:
                    result['error'] = f"HTTP çŠ¶æ€ç : {response.status}"
        except aiohttp.client_exceptions.ProxyConnectionError as e:
            result['error'] = f"ä»£ç†è¿æ¥å¤±è´¥: {e}"
        except aiohttp.client_exceptions.ClientConnectorError as e:
            result['error'] = f"å®¢æˆ·ç«¯è¿æ¥é”™è¯¯: {e}"
        except asyncio.TimeoutError:
            result['error'] = "æµ‹è¯•è¶…æ—¶"
        except Exception as e:
            result['error'] = str(e)
            
        # å¦‚æœä»£ç†ä¸å¯ç”¨ï¼Œå°è¯•ä» Clash è¿›ç¨‹çš„æ ‡å‡†é”™è¯¯è¾“å‡ºä¸­è·å–æ›´å¤šä¿¡æ¯
        if result['status'] == 'ä¸å¯ç”¨' and proc.poll() is None: # ä»…å½“ Clash ä»åœ¨è¿è¡Œæ—¶
            try:
                # ç»™ Clash ä¸€äº›æ—¶é—´å†™å…¥æ—¥å¿—ï¼Œç„¶åå°è¯•è¯»å–å…¶é”™è¯¯è¾“å‡º
                await asyncio.sleep(1) 
                stdout, stderr = proc.communicate(timeout=1)
                clash_log = stderr.decode(errors='ignore').strip()
                if clash_log:
                    result['error'] += f" | Clash æ—¥å¿—: {clash_log}"
            except subprocess.TimeoutExpired:
                proc.kill() # å¦‚æœè¶…æ—¶ï¼Œåˆ™å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹
                stdout, stderr = proc.communicate()
                clash_log = stderr.decode(errors='ignore').strip()
                if clash_log:
                    result['error'] += f" | Clash æ—¥å¿— (å¼ºåˆ¶ç»ˆæ­¢): {clash_log}"
            except Exception as log_e:
                result['error'] += f" | è¯»å– Clash æ—¥å¿—å¤±è´¥: {log_e}"

    except FileNotFoundError:
        result['error'] = f"Clash å¯æ‰§è¡Œæ–‡ä»¶æœªæ‰¾åˆ°: {clash_bin}. è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ä¸”æ–‡ä»¶å¯æ‰§è¡Œã€‚"
    except Exception as e:
        result['error'] = f"å¯åŠ¨ Clash æˆ–é…ç½®ç”Ÿæˆå¤±è´¥: {str(e)}"
    finally:
        # ç¡®ä¿ Clash è¿›ç¨‹è¢«ç»ˆæ­¢
        if proc and proc.poll() is None: # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
            proc.terminate() # å°è¯•æ­£å¸¸ç»ˆæ­¢
            try:
                await asyncio.wait_for(proc.wait(), timeout=1) # ç­‰å¾…è¿›ç¨‹ç»ˆæ­¢
            except asyncio.TimeoutError:
                proc.kill() # å¦‚æœè¶…æ—¶ï¼Œåˆ™å¼ºåˆ¶æ€æ­»è¿›ç¨‹
        # åˆ é™¤ä¸´æ—¶é…ç½®æ–‡ä»¶
        if config_path and os.path.exists(config_path):
            try:
                os.remove(config_path)
            except Exception as e:
                logger.warning(f"åˆ é™¤é…ç½®æ–‡ä»¶ {config_path} å¤±è´¥: {e}")
    
    logger.info(f"ğŸ”’ {proxy.get('type', 'UNKNOWN').upper()}-{proxy.get('network', 'TCP').upper()}-{'TLS' if proxy.get('sni') else 'NA'} "
                f"{proxy.get('name', 'Unnamed')}: {result['status']}, å»¶è¿Ÿ: {result['latency']:.2f}ms")
    return result

async def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œä»£ç†æµ‹è¯•"""
    parser = argparse.ArgumentParser(description='æµ‹è¯•ä»£ç†èŠ‚ç‚¹')
    parser.add_argument('--proxy-url', default='https://raw.githubusercontent.com/qjlxg/aggregator/refs/heads/main/ss.txt',
                        help='ä»£ç†èŠ‚ç‚¹ URL')
    parser.add_argument('--clash-bin', default='./tools/clash', help='Clash äºŒè¿›åˆ¶è·¯å¾„')
    # è°ƒæ•´æ‰¹é‡æµ‹è¯•èŠ‚ç‚¹æ•°ï¼Œé€šå¸¸ä¸å®œè¿‡é«˜ï¼Œé¿å…èµ„æºè€—å°½
    parser.add_argument('--batch-size', type=int, default=max(10, psutil.cpu_count() * 2), help='æ‰¹é‡æµ‹è¯•èŠ‚ç‚¹æ•°') 
    parser.add_argument('--invalid-file', default='data/invalid_nodes.yaml', help='ä¸å¯ç”¨èŠ‚ç‚¹æ–‡ä»¶')
    parser.add_argument('--valid-file', default='data/521.yaml', help='å¯ç”¨èŠ‚ç‚¹æ–‡ä»¶')
    parser.add_argument('--expire-days', type=int, default=7, help='ä¸å¯ç”¨èŠ‚ç‚¹è¿‡æœŸå¤©æ•°')
    args = parser.parse_args()

    os.makedirs('data', exist_ok=True)
    
    # åŠ è½½ä¸Šæ¬¡çš„ä¸å¯ç”¨å’Œå¯ç”¨èŠ‚ç‚¹
    invalid_nodes = load_invalid_nodes(args.invalid_file)
    valid_nodes = load_invalid_nodes(args.valid_file)
    
    # è¿‡æ»¤æ‰ä»»ä½•æ— æ³•ç”Ÿæˆæœ‰æ•ˆé”®çš„èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ï¼Œæ ¼å¼é”™è¯¯çš„èŠ‚ç‚¹ï¼‰
    invalid_keys = {get_node_key(node) for node in invalid_nodes if get_node_key(node)}
    valid_keys = {get_node_key(node) for node in valid_nodes if get_node_key(node)}

    async with aiohttp.ClientSession() as session:
        # è·å–æœ€æ–°èŠ‚ç‚¹
        proxies = await fetch_proxies(args.proxy_url)
        if not proxies:
            logger.error("æ²¡æœ‰å¯æµ‹è¯•çš„ä»£ç†èŠ‚ç‚¹")
            return

        # è¿‡æ»¤æ–°å¢èŠ‚ç‚¹ï¼Œç¡®ä¿åªæœ‰æœ‰æ•ˆçš„ä¸”æœªæ›¾æµ‹è¯•è¿‡çš„èŠ‚ç‚¹è¢«åŠ å…¥
        new_proxies = [p for p in proxies if get_node_key(p) and get_node_key(p) not in invalid_keys and get_node_key(p) not in valid_keys]
        logger.info(f"æ€»èŠ‚ç‚¹æ•°: {len(proxies)}, æ–°å¢èŠ‚ç‚¹: {len(new_proxies)}, å·²çŸ¥å¯ç”¨: {len(valid_nodes)}, å·²çŸ¥ä¸å¯ç”¨: {len(invalid_nodes)}")

        # æµ‹è¯•æ–°å¢èŠ‚ç‚¹
        results = []
        base_port = get_free_port()
        for i in range(0, len(new_proxies), args.batch_size):
            batch = new_proxies[i:i + args.batch_size]
            # ä¸ºæ‰¹å¤„ç†ä¸­çš„æ¯ä¸ª Clash å®ä¾‹ç¡®ä¿å”¯ä¸€çš„ç«¯å£ï¼Œé¿å…å†²çª
            tasks = [test_proxy(proxy, session, args.clash_bin, base_port + (j + i) * 3) for j, proxy in enumerate(batch)]
            batch_results = await asyncio.gather(*tasks)
            results.extend(batch_results)

        # åˆå¹¶ç»“æœå¹¶è¿›è¡Œå»é‡
        new_valid = [r['proxy'] for r in results if r['status'] == 'å¯ç”¨']
        new_invalid = [r['proxy'] for r in results if r['status'] == 'ä¸å¯ç”¨']
        
        # æ›´æ–°å¯ç”¨èŠ‚ç‚¹ï¼ˆä¿ç•™æ—§çš„å¯ç”¨èŠ‚ç‚¹ + æ–°æµ‹è¯•çš„å¯ç”¨èŠ‚ç‚¹ï¼‰
        # ä½¿ç”¨å­—å…¸è¿›è¡Œå»é‡ï¼Œé”®æ˜¯èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†
        all_valid_temp = {}
        for node in valid_nodes:
            key = get_node_key(node)
            if key:
                all_valid_temp[key] = node
        for node in new_valid:
            key = get_node_key(node)
            if key:
                all_valid_temp[key] = node
        all_valid = list(all_valid_temp.values())

        # æ›´æ–°ä¸å¯ç”¨èŠ‚ç‚¹ï¼ˆä¿ç•™æœªè¿‡æœŸçš„æ—§èŠ‚ç‚¹ + æ–°æµ‹è¯•çš„ä¸å¯ç”¨èŠ‚ç‚¹ï¼‰
        expire_time = datetime.now() - timedelta(days=args.expire_days)
        all_invalid_temp = {}
        for node in invalid_nodes:
            key = get_node_key(node)
            # ä»…ä¿ç•™æœªè¿‡æœŸçš„æ—§ä¸å¯ç”¨èŠ‚ç‚¹
            if key and 'tested_at' in node and datetime.fromisoformat(node['tested_at']) > expire_time:
                all_invalid_temp[key] = node
        for node in new_invalid:
            key = get_node_key(node)
            if key:
                all_invalid_temp[key] = node
        all_invalid = list(all_invalid_temp.values())

        # ä¿å­˜ç»“æœ
        await save_nodes(args.valid_file, all_valid)
        await save_nodes(args.invalid_file, all_invalid)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        if proxies: # é¿å…é™¤ä»¥é›¶
            logger.info(f"æµ‹è¯•å®Œæˆ: æ€»èŠ‚ç‚¹æ•°={len(proxies)}, å¯ç”¨èŠ‚ç‚¹={len(all_valid)}, "
                        f"ä¸å¯ç”¨èŠ‚ç‚¹={len(all_invalid)}, å¯ç”¨ç‡={len(all_valid)/len(proxies)*100:.2f}%")
        else:
            logger.info(f"æµ‹è¯•å®Œæˆ: æ²¡æœ‰ä»£ç†èŠ‚ç‚¹å¯ä¾›æµ‹è¯•ã€‚")

if __name__ == '__main__':
    asyncio.run(main())
