import os
import re
import base64
import json
import yaml
import time
import requests
import sys
from urllib.parse import urlparse, parse_qs, unquote # å¯¼å…¥ unquote

# èŠ‚ç‚¹ä¸‹è½½ URL
NODE_URL = "https://raw.githubusercontent.com/qjlxg/vt/refs/heads/main/data/success_count.txt"
# Mihomo æ§åˆ¶å™¨åœ°å€
MIHOMO_CONTROLLER_URL = "http://127.0.0.1:9090"
# Mihomo Socks5 ä»£ç†åœ°å€
MIHOMO_SOCKS5_PROXY = "socks5h://127.0.0.1:7891"
# Mihomo é…ç½®æ–‡ä»¶è·¯å¾„
MIHOMO_CONFIG_PATH = "config.yaml"
# æˆåŠŸèŠ‚ç‚¹ä¿å­˜è·¯å¾„
SUCCESS_NODES_PATH = "data/all.txt"

def parse_vmess(link):
    """è§£æ vmess é“¾æ¥"""
    try:
        encoded_str = link.replace("vmess://", "")
        # vmess é“¾æ¥æ˜¯ base64(json) æ ¼å¼ï¼Œä½†æœ‰æ—¶ä¸æ˜¯æ ‡å‡† base64
        # å°è¯•æ ‡å‡† base64 è§£ç ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯• urlsafe è§£ç 
        try:
            decoded_bytes = base64.b64decode(encoded_str)
        except Exception:
            decoded_bytes = base64.urlsafe_b64decode(encoded_str + "=" * ((4 - len(encoded_str) % 4) % 4))
        
        config = json.loads(decoded_bytes.decode('utf-8'))
        
        # è§£ç èŠ‚ç‚¹åç§°ä¸­çš„URLç¼–ç 
        name = unquote(config.get("ps", f"vmess_{config.get('add', 'unknown')}"))
        
        return {
            "name": name,
            "type": "vmess",
            "server": config.get("add"),
            "port": int(config.get("port")),
            "uuid": config.get("id"),
            "alterId": int(config.get("aid", 0)),
            "security": config.get("scy", "auto"),
            "network": config.get("net", "tcp"),
            "tls": config.get("tls", "") == "tls",
            "sni": config.get("sni", ""),
            "ws-path": config.get("path", ""),
            "ws-headers": {"Host": config.get("host", "")}
        }
    except Exception as e:
        print(f"Error parsing vmess link '{link}': {e}")
        return None

def parse_trojan(link):
    """è§£æ trojan é“¾æ¥"""
    # trojan://password@server:port?params#name
    match = re.match(r"trojan://([^@]+)@([^:]+):(\d+)(.*)", link)
    if match:
        password = match.group(1)
        server = match.group(2)
        port = int(match.group(3))
        
        # è§£æ # åé¢çš„åç§°
        name_match = re.search(r"#([^#&]+)", link)
        name = unquote(name_match.group(1)) if name_match else f"trojan_{server}"

        # è¿›ä¸€æ­¥è§£ææŸ¥è¯¢å‚æ•°ï¼Œä¾‹å¦‚ sni
        parsed_url = urlparse(link)
        query_params = parse_qs(parsed_url.query)
        sni = query_params.get('sni', [None])[0]

        trojan_config = {
            "name": name,
            "type": "trojan",
            "server": server,
            "port": port,
            "password": password
        }
        if sni:
            trojan_config["sni"] = sni
            trojan_config["tls"] = True # trojan é»˜è®¤å¸¦ tls

        return trojan_config
    return None

def parse_ss(link):
    """è§£æ ss é“¾æ¥"""
    try:
        # ss://base64(method:password@server:port)#name
        # ç§»é™¤éç¼–ç éƒ¨åˆ†çš„åç§°
        link_parts = link.replace("ss://", "").split('#', 1)
        encoded_part = link_parts[0]
        
        # å°è¯•é²æ£’çš„ Base64 è§£ç ï¼Œå¤„ç†éæ ‡å‡†å¡«å……
        decoded_bytes = base64.urlsafe_b64decode(encoded_part + "=" * ((4 - len(encoded_part) % 4) % 4))
        decoded_str = decoded_bytes.decode('utf-8')
        
        parts = decoded_str.split('@')
        if len(parts) == 2:
            auth_part = parts[0]
            server_port_part = parts[1]

            method, password = auth_part.split(':', 1)
            server, port = server_port_part.rsplit(':', 1)

            # æå–åç§°ï¼Œå¹¶è¿›è¡ŒURLè§£ç 
            name = unquote(link_parts[1]) if len(link_parts) > 1 else f"ss_{server}"

            return {
                "name": name,
                "type": "ss",
                "server": server,
                "port": int(port),
                "cipher": method,
                "password": password
            }
    except Exception as e:
        print(f"Error parsing ss link '{link}': {e}")
    return None

def parse_hysteria2(link):
    """è§£æ hysteria2 é“¾æ¥"""
    # å…è®¸ hy2:// æˆ– hysteria2://
    link = link.replace("hy2://", "hysteria2://") 
    
    # hysteria2://password@server:port?obfs=obfs_name&obfs-password=obfs_pass#name
    match = re.match(r"hysteria2://([^@]+)@([^:]+):(\d+)(\?.*)?(#(.*))?", link)
    if match:
        password = match.group(1)
        server = match.group(2)
        port = int(match.group(3))
        query_string = match.group(4) if match.group(4) else ""
        
        # è§£ç åç§°
        name = unquote(match.group(6)) if match.group(6) else f"hysteria2_{server}"

        params = {}
        if query_string:
            for param in query_string[1:].split('&'):
                if '=' in param: # ç¡®ä¿å‚æ•°æ˜¯é”®å€¼å¯¹
                    key, value = param.split('=', 1)
                    params[key] = value
        
        return {
            "name": name,
            "type": "hysteria2",
            "server": server,
            "port": port,
            "password": password,
            "obfs": params.get("obfs"),
            "obfs-password": params.get("obfs-password"),
            "up": int(params.get("up", 0)),
            "down": int(params.get("down", 0)),
            "alpn": params.get("alpn"),
            "tls": params.get("insecure") != "1", # insecure=1 è¡¨ç¤ºä¸å®‰å…¨
            "sni": params.get("sni")
        }
    return None

def parse_vless(link):
    """è§£æ vless é“¾æ¥"""
    # vless://UUID@SERVER:PORT?params#NAME
    match = re.match(r"vless://([^@]+)@([^:]+):(\d+)(\?.*)?(#(.*))?", link)
    if match:
        uuid = match.group(1)
        server = match.group(2)
        port = int(match.group(3))
        query_string = match.group(4) if match.group(4) else ""
        
        # è§£ç åç§°
        name = unquote(match.group(6)) if match.group(6) else f"vless_{server}"

        params = {}
        if query_string:
            for param in query_string[1:].split('&'):
                if '=' in param:
                    key, value = param.split('=', 1)
                    params[key] = value

        vless_config = {
            "name": name,
            "type": "vless",
            "server": server,
            "port": port,
            "uuid": uuid,
            "network": params.get("type", "tcp"),
            "tls": params.get("security", "") == "tls",
            "flow": params.get("flow", ""),
            "udp": True # VLESSé€šå¸¸æ”¯æŒUDP
        }

        if params.get("security") == "reality":
            vless_config["reality-opts"] = {
                "dest": params.get("dest", ""), # dest = host:port
                "xver": int(params.get("xver", 0)),
                "sni": params.get("sni", ""),
                "fingerprint": params.get("fp", ""), # reality fingerprint
                "publicKey": params.get("pbk", "") # reality public key
            }
        
        # WebSocket settings
        if vless_config["network"] == "ws":
            vless_config["ws-path"] = params.get("path", "")
            vless_config["ws-headers"] = {"Host": params.get("host", "")}
        
        return vless_config
    return None


def parse_node_link(link):
    """æ ¹æ®åè®®ç±»å‹è§£æèŠ‚ç‚¹é“¾æ¥"""
    if link.startswith("vmess://"):
        return parse_vmess(link)
    elif link.startswith("trojan://"):
        return parse_trojan(link)
    elif link.startswith("ss://"):
        return parse_ss(link)
    elif link.startswith("hysteria2://") or link.startswith("hy2://"): # å…¼å®¹ hy2://
        return parse_hysteria2(link)
    elif link.startswith("vless://"):
        return parse_vless(link)
    # TODO: æ·»åŠ  SSR è§£æé€»è¾‘ï¼ŒSSR é€šå¸¸éœ€è¦æ›´å¤æ‚çš„è§£æåº“
    elif link.startswith("ssr://"):
        print(f"Skipping SSR link (complex parsing not implemented): {link}")
        return None
    else:
        print(f"Unknown protocol or invalid link: {link}")
        return None

def generate_mihomo_config(parsed_nodes):
    """ç”Ÿæˆ Mihomo é…ç½®æ–‡ä»¶"""
    config = {
        "port": 7890,
        "socks-port": 7891,
        "redir-port": 7892,
        "tproxy-port": 7893,
        "mixed-port": 7890,
        "mode": "rule",
        "log-level": "info",
        "allow-lan": False,
        "bind-address": "127.0.0.1",
        "external-controller": "127.0.0.1:9090",
        "dns": {
            "enable": True,
            "listen": "0.0.0.0:53",
            "default-nameserver": ["114.114.114.114", "8.8.8.8"],
            "enhanced-mode": "fake-ip",
            "fake-ip-range": "198.18.0.1/16",
            "use-hosts": True,
            "fallback": ["tls://1.1.1.1:853", "tls://8.8.8.8:853"],
            "fallback-filter": {
                "geoip": True,
                "ipcidr": ["240.0.0.0/4"]
            }
        },
        "proxies": [],
        "proxy-groups": [
            {
                "name": "ğŸ”° èŠ‚ç‚¹é€‰æ‹©",
                "type": "select",
                "proxies": ["DIRECT"]
            }
        ],
        "rules": ["MATCH,ğŸ”° èŠ‚ç‚¹é€‰æ‹©"]
    }

    proxy_names = []
    for node in parsed_nodes:
        if node: # ç¡®ä¿èŠ‚ç‚¹è§£ææˆåŠŸ
            config["proxies"].append(node)
            proxy_names.append(node["name"])
    
    # å°†æ‰€æœ‰è§£æå‡ºçš„ä»£ç†æ·»åŠ åˆ°èŠ‚ç‚¹é€‰æ‹©ç»„ä¸­
    config["proxy-groups"][0]["proxies"].extend(proxy_names)

    with open(MIHOMO_CONFIG_PATH, "w", encoding="utf-8") as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False)
    print(f"Generated Mihomo config: {MIHOMO_CONFIG_PATH}")

def test_nodes(original_links_map):
    """æµ‹è¯•èŠ‚ç‚¹è¿æ¥"""
    successful_nodes = []
    
    # ä»ç”Ÿæˆçš„é…ç½®ä¸­è¯»å–ä»£ç†åç§°
    with open(MIHOMO_CONFIG_PATH, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    proxies = config.get("proxies", [])
    
    print("Starting node testing...")
    for proxy in proxies:
        proxy_name = proxy["name"]
        
        print(f"Testing node: {proxy_name}...")
        try:
            # åˆ‡æ¢ Mihomo ä»£ç†
            # ç¡®ä¿ Mihomo æ§åˆ¶å™¨æ˜¯å¯è¾¾çš„ï¼Œå¢åŠ é‡è¯•æœºåˆ¶
            for _ in range(3): # å°è¯•3æ¬¡è¿æ¥ Mihomo API
                try:
                    response = requests.put(
                        f"{MIHOMO_CONTROLLER_URL}/proxies/%E2%9C%A8%20%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9",
                        json={"name": proxy_name},
                        timeout=5
                    )
                    response.raise_for_status()
                    break # æˆåŠŸè¿æ¥å¹¶åˆ‡æ¢ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                except requests.exceptions.ConnectionError:
                    print(f"Connection to Mihomo controller refused, retrying...")
                    time.sleep(2) # ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
            else:
                raise ConnectionError("Failed to connect to Mihomo controller after multiple retries.")
            
            time.sleep(1) # ç­‰å¾…ä»£ç†åˆ‡æ¢

            # ä½¿ç”¨ Mihomo ä»£ç†æµ‹è¯• Google
            test_response = requests.get(
                "https://www.google.com",
                proxies={"http": MIHOMO_SOCKS5_PROXY, "https": MIHOMO_SOCKS5_PROXY},
                timeout=10
            )
            test_response.raise_for_status()
            print(f"âœ… Node '{proxy_name}' is working.")
            
            # æ‰¾åˆ°åŸå§‹é“¾æ¥å¹¶ä¿å­˜
            if proxy_name in original_links_map:
                successful_nodes.append(original_links_map[proxy_name])
            else:
                print(f"Warning: Could not find original link for proxy name '{proxy_name}' in map. Skipping.")
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ Node '{proxy_name}' is NOT working. Error: {e}")
        except Exception as e:
            print(f"An unexpected error occurred during testing node '{proxy_name}': {e}")
            
    return successful_nodes

def main():
    # 1. ä¸‹è½½èŠ‚ç‚¹
    print(f"Downloading nodes from {NODE_URL}...")
    try:
        response = requests.get(NODE_URL, timeout=10)
        response.raise_for_status() # æ£€æŸ¥ HTTP é”™è¯¯
        node_links = response.text.strip().split('\n')
        node_links = [link.strip() for link in node_links if link.strip()] # è¿‡æ»¤ç©ºè¡Œ
        print(f"Downloaded {len(node_links)} nodes.")
    except requests.exceptions.RequestException as e:
        print(f"Error downloading nodes: {e}")
        sys.exit(1)

    if not node_links:
        print("No nodes found in the downloaded file. Exiting.")
        sys.exit(0)

    # 2. è§£æèŠ‚ç‚¹
    parsed_nodes = []
    original_links_map = {} # ç”¨äºå­˜å‚¨ä»£ç†åç§°åˆ°åŸå§‹é“¾æ¥çš„æ˜ å°„
    for i, link in enumerate(node_links):
        parsed = parse_node_link(link)
        if parsed:
            # ç¡®ä¿åç§°å”¯ä¸€
            original_name_for_map = parsed["name"] # ç”¨åŸå§‹è§£æçš„åç§°ä½œä¸ºkey
            unique_name_for_mihomo_config = original_name_for_map
            count = 1
            while unique_name_for_mihomo_config in [p["name"] for p in parsed_nodes]:
                unique_name_for_mihomo_config = f"{original_name_for_map}_{count}"
                count += 1
            
            parsed["name"] = unique_name_for_mihomo_config
            
            parsed_nodes.append(parsed)
            # è¿™é‡Œçš„ original_links_map åº”è¯¥å­˜å‚¨çš„æ˜¯ Mihomo é…ç½®ä¸­çš„å”¯ä¸€åç§°åˆ°åŸå§‹é“¾æ¥çš„æ˜ å°„
            original_links_map[unique_name_for_mihomo_config] = link
    
    if not parsed_nodes:
        print("No valid nodes parsed. Exiting.")
        sys.exit(0)

    # 3. ç”Ÿæˆ Mihomo é…ç½®
    generate_mihomo_config(parsed_nodes)

    # 4. å¯åŠ¨ Mihomo (åœ¨ GitHub Actions ä¸­ç”±å¤–éƒ¨è„šæœ¬å¯åŠ¨)
    # æ­¤è„šæœ¬ä»…è´Ÿè´£ç”Ÿæˆé…ç½®å’Œæµ‹è¯•ï¼ŒMihomo çš„å¯åŠ¨å’Œåœæ­¢ç”± GH Actions å·¥ä½œæµå¤„ç†

    # 5. æµ‹è¯•èŠ‚ç‚¹
    successful_nodes = test_nodes(original_links_map)

    # 6. ä¿å­˜æˆåŠŸèŠ‚ç‚¹
    os.makedirs(os.path.dirname(SUCCESS_NODES_PATH), exist_ok=True)
    with open(SUCCESS_NODES_PATH, "w", encoding="utf-8") as f:
        for node_link in successful_nodes:
            f.write(f"{node_link}\n")
    print(f"Successfully saved {len(successful_nodes)} working nodes to {SUCCESS_NODES_PATH}")

if __name__ == "__main__":
    main()
