import httpx
import yaml
import asyncio
import base64
import json
import os
import urllib.parse
import subprocess
import time

# å°†ä½ çš„æ¥æºé“¾æ¥è®¾ç½®ä¸ºé»˜è®¤å€¼ã€‚
CLASH_BASE_CONFIG_URLS = [
    "https://snippet.host/oouyda/raw"
]

# --- parse_node_link_to_clash_proxy å‡½æ•° ---
def parse_node_link_to_clash_proxy(link: str) -> dict | None:
    """
    å°è¯•å°†ä¸€ä¸ªæ˜æ–‡èŠ‚ç‚¹é“¾æ¥ï¼ˆss, vmess, trojan, hy2, vlessç­‰ï¼‰
    è§£ææˆClashä»£ç†å­—å…¸æ ¼å¼ã€‚
    """
    if not link or "://" not in link:
        return None

    try:
        scheme, remainder = link.split("://", 1)
        name_part = None
        if "#" in remainder:
            remainder, name_part = remainder.split("#", 1)
            name_part = urllib.parse.unquote(name_part)

        proxy = {"name": name_part if name_part else f"{scheme} Node", "type": scheme}

        if scheme == "ss":
            try:
                # å°è¯•ä¿®å¤ Base64 å¡«å……é—®é¢˜ï¼Œå¹¶æ•è·è§£ç é”™è¯¯
                base64_part_raw = remainder.split("@", 1)[0]
                # Base64 å­—ç¬¦ä¸²çš„é•¿åº¦å¿…é¡»æ˜¯ 4 çš„å€æ•°ï¼Œä¸è¶³æ—¶å¡«å…… '='
                missing_padding = len(base64_part_raw) % 4
                if missing_padding != 0:
                    base64_part = base64_part_raw + '=' * (4 - missing_padding)
                else:
                    base64_part = base64_part_raw

                decoded_userinfo = base64.urlsafe_b64decode(base64_part).decode()
                method, password = decoded_userinfo.split(":", 1)
                server_port = remainder.split("@", 1)[1]
                server, port = server_port.split(":", 1)

                proxy.update({
                    "type": "ss",
                    "server": server,
                    "port": int(port),
                    "cipher": method,
                    "password": password
                })
            except (base64.binascii.Error, ValueError, IndexError) as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æSSé“¾æ¥å¤±è´¥ï¼ˆBase64è§£ç æˆ–æ ¼å¼é—®é¢˜ï¼‰ï¼š{link} - {e}")
                return None
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æSSé“¾æ¥å¤±è´¥ï¼š{link} - {e}")
                return None
        elif scheme == "vmess":
            try:
                # å°è¯•ä¿®å¤ Base64 å¡«å……é—®é¢˜ï¼Œå¹¶æ•è·è§£ç é”™è¯¯
                vmess_base64_raw = remainder
                missing_padding = len(vmess_base64_raw) % 4
                if missing_padding != 0:
                    vmess_base64 = vmess_base64_raw + '=' * (4 - missing_padding)
                else:
                    vmess_base64 = vmess_base64_raw

                decoded_json_str = base64.urlsafe_b64decode(vmess_base64).decode('utf-8')
                vmess_config = json.loads(decoded_json_str)

                proxy.update({
                    "type": "vmess",
                    "server": vmess_config.get("add"),
                    "port": int(vmess_config.get("port")),
                    "uuid": vmess_config.get("id"),
                    "alterId": int(vmess_config.get("aid", 0)),
                    "cipher": vmess_config.get("scy", "auto"),
                    "network": vmess_config.get("net", "tcp"),
                    "tls": vmess_config.get("tls") == "tls",
                    "servername": vmess_config.get("sni"),
                    "ws-path": vmess_config.get("path", "/"),
                    "ws-headers": {"Host": vmess_config.get("host")} if vmess_config.get("host") else {}
                })
                proxy = {k: v for k, v in proxy.items() if v not in [None, '', {}]}
            except (base64.binascii.Error, ValueError, json.JSONDecodeError, IndexError) as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æVmessé“¾æ¥å¤±è´¥ï¼ˆBase64è§£ç æˆ–JSONæ ¼å¼é—®é¢˜ï¼‰ï¼š{link} - {e}")
                return None
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æVmessé“¾æ¥å¤±è´¥ï¼š{link} - {e}")
                return None
        elif scheme == "trojan":
            try:
                password_server_port, query_params_str = remainder.split("?", 1) if "?" in remainder else (remainder, "")
                password, server_port = password_server_port.split("@", 1)
                server, port = server_port.split(":", 1)

                proxy.update({
                    "type": "trojan",
                    "server": server,
                    "port": int(port),
                    "password": urllib.parse.unquote(password)
                })

                if query_params_str:
                    query_params = urllib.parse.parse_qs(query_params_str)
                    if "security" in query_params and query_params["security"][0] == "tls":
                        proxy["tls"] = True
                    if "sni" in query_params:
                        proxy["servername"] = query_params["sni"][0]
                    if "allowInsecure" in query_params and query_params["allowInsecure"][0] == "1":
                        proxy["skip-cert-verify"] = True
                    if "type" in query_params:
                        proxy["network"] = query_params["type"][0]
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æTrojané“¾æ¥å¤±è´¥ï¼š{link} - {e}")
                return None
        elif scheme == "hy2":
            try:
                password_server_port, query_params_str = remainder.split("?", 1) if "?" in remainder else (remainder, "")
                password_encoded, server_port = password_server_port.split("@", 1)
                server, port = server_port.split(":", 1)

                proxy.update({
                    "type": "hysteria2",
                    "server": server,
                    "port": int(port),
                    "password": password_encoded,
                })

                if query_params_str:
                    query_params = urllib.parse.parse_qs(query_params_str)
                    if "insecure" in query_params and query_params["insecure"][0] == "1":
                        proxy["skip-cert-verify"] = True
                    if "sni" in query_params:
                        proxy["servername"] = query_params["sni"][0]
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æHysteria2é“¾æ¥å¤±è´¥ï¼š{link} - {e}")
                return None
        elif scheme == "vless":
            try:
                uuid_server_port, query_params_str = remainder.split("?", 1) if "?" in remainder else (remainder, "")
                uuid, server_port = uuid_server_port.split("@", 1)
                server, port = server_port.split(":", 1)

                proxy.update({
                    "type": "vless",
                    "server": server,
                    "port": int(port),
                    "uuid": uuid,
                    "cipher": "auto"
                })

                if query_params_str:
                    query_params = urllib.parse.parse_qs(query_params_str)
                    if "security" in query_params and query_params["security"][0] == "tls":
                        proxy["tls"] = True
                    if "sni" in query_params:
                        proxy["servername"] = query_params["sni"][0]
                    if "type" in query_params:
                        proxy["network"] = query_params["type"][0]
                    if "path" in query_params:
                        proxy["ws-path"] = query_params["path"][0]
                    if "host" in query_params:
                        proxy["ws-headers"] = {"Host": query_params["host"][0]}
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šè§£æVlessé“¾æ¥å¤±è´¥ï¼š{link} - {e}")
                return None
        else:
            print(f"âš ï¸ è­¦å‘Šï¼šè·³è¿‡ä¸æ”¯æŒçš„åè®®ç±»å‹ï¼š{scheme} (é“¾æ¥: {link})")
            return None

        if not proxy.get("name") and name_part:
             proxy["name"] = name_part
        elif not proxy.get("name"):
            proxy["name"] = f"{proxy.get('type', 'unknown').upper()}-{proxy.get('server', 'unknown')}:{proxy.get('port', 'unknown')}"

        return proxy

    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šè§£ææœªçŸ¥é“¾æ¥æ ¼å¼å¤±è´¥ï¼š{link} - {e}")
        return None

# --- fetch_all_configs å‡½æ•° ---
async def fetch_all_configs(urls: list[str]) -> list:
    """
    ä»ç»™å®šçš„ URL åˆ—è¡¨ä¸­è·å–çº¯æ–‡æœ¬èŠ‚ç‚¹é“¾æ¥ï¼Œå¹¶å°è¯•è§£ææˆClashä»£ç†å­—å…¸ã€‚
    """
    all_proxies = []
    async with httpx.AsyncClient() as client:
        for url in urls:
            try:
                print(f"ğŸ”„ æ­£åœ¨ä» {url} è·å–èŠ‚ç‚¹é“¾æ¥åˆ—è¡¨...")
                response = await client.get(url, timeout=20)
                response.raise_for_status()
                node_links_content = response.text

                lines = node_links_content.strip().split("\n")
                
                parsed_count = 0
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    proxy_obj = parse_node_link_to_clash_proxy(line)
                    if proxy_obj:
                        all_proxies.append(proxy_obj)
                        parsed_count += 1
                
                print(f"âœ… æˆåŠŸä» {url} è§£æåˆ° {parsed_count} ä¸ªä»£ç†èŠ‚ç‚¹ã€‚")

            except httpx.RequestError as e:
                print(f"âŒ é”™è¯¯ï¼šä» {url} è·å–èŠ‚ç‚¹é“¾æ¥å¤±è´¥ï¼š{e}")
            except Exception as e:
                print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œå¤„ç† {url} æ—¶å‡ºç°ï¼š{e}")
    return all_proxies

# --- generate_plaintext_node_link å‡½æ•° ---
def generate_plaintext_node_link(proxy: dict) -> str | None:
    """
    æ ¹æ®Clashä»£ç†å­—å…¸ç”Ÿæˆæ˜æ–‡èŠ‚ç‚¹é“¾æ¥ï¼ˆä¾‹å¦‚ ss://, vmess://ï¼‰ã€‚
    """
    p_type = proxy.get("type")
    p_name = proxy.get("name", "Unnamed Node")

    if p_type == "ss":
        server = proxy.get("server")
        port = proxy.get("port")
        password = proxy.get("password")
        cipher = proxy.get("cipher")
        if all([server, port, password, cipher]):
            userinfo = f"{cipher}:{password}@{server}:{port}"
            encoded_userinfo = base64.urlsafe_b64encode(userinfo.encode()).decode().rstrip('=')
            safe_name = urllib.parse.quote(p_name)
            return f"ss://{encoded_userinfo}#{safe_name}"
    elif p_type == "vmess":
        server = proxy.get("server")
        port = proxy.get("port")
        uuid = proxy.get("uuid")
        alterId = proxy.get("alterId", 0)
        cipher = proxy.get("cipher", "auto")
        network = proxy.get("network", "tcp")
        tls = proxy.get("tls", False)
        servername = proxy.get("servername", "")
        ws_path = proxy.get("ws-path", "")
        ws_headers = proxy.get("ws-headers", {}).get("Host", "")

        if all([server, port, uuid]):
            vmess_obj = {
                "v": "2",
                "ps": p_name,
                "add": server,
                "port": str(port),
                "id": uuid,
                "aid": str(alterId),
                "scy": cipher,
                "net": network,
            }
            if ws_path: vmess_obj["path"] = ws_path
            if ws_headers: vmess_obj["host"] = ws_headers
            if tls: vmess_obj["tls"] = "tls"
            if servername: vmess_obj["sni"] = servername

            vmess_obj = {k: v for k, v in vmess_obj.items() if v}
            
            try:
                vmess_json = json.dumps(vmess_obj, ensure_ascii=False)
                encoded_vmess = base64.urlsafe_b64encode(vmess_json.encode('utf-8')).decode('utf-8').rstrip('=')
                return f"vmess://{encoded_vmess}"
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šç”Ÿæˆ Vmess é“¾æ¥å¤±è´¥ï¼ŒèŠ‚ç‚¹ï¼š{p_name}ï¼Œé”™è¯¯ï¼š{e}")
                return None
    elif p_type == "trojan":
        server = proxy.get("server")
        port = proxy.get("port")
        password = proxy.get("password")
        tls = proxy.get("tls", False)
        sni = proxy.get("servername", "")
        skip_cert_verify = proxy.get("skip-cert-verify", False)
        network = proxy.get("network", "tcp")

        if all([server, port, password]):
            params = []
            if tls:
                params.append("security=tls")
            if sni:
                params.append(f"sni={sni}")
            if skip_cert_verify:
                params.append("allowInsecure=1")
            if network != "tcp":
                params.append(f"type={network}")
            
            param_str = "&".join(params)
            encoded_password = urllib.parse.quote(password)
            safe_name = urllib.parse.quote(p_name)
            
            link = f"trojan://{encoded_password}@{server}:{port}"
            if param_str:
                link += f"?{param_str}"
            link += f"#{safe_name}"
            return link
    elif p_type == "hy2":
        server = proxy.get("server")
        port = proxy.get("port")
        password = proxy.get("password")
        skip_cert_verify = proxy.get("skip-cert-verify", False)
        servername = proxy.get("servername", "")

        if all([server, port, password]):
            params = []
            if skip_cert_verify:
                params.append("insecure=1")
            if servername:
                params.append(f"sni={servername}")
            
            param_str = "&".join(params)
            encoded_password = urllib.parse.quote(password)
            safe_name = urllib.parse.quote(p_name)

            link = f"hy2://{encoded_password}@{server}:{port}"
            if param_str:
                link += f"?{param_str}"
            link += f"#{safe_name}"
            return link
    elif p_type == "vless":
        server = proxy.get("server")
        port = proxy.get("port")
        uuid = proxy.get("uuid")
        tls = proxy.get("tls", False)
        servername = proxy.get("servername", "")
        network = proxy.get("network", "tcp")
        ws_path = proxy.get("ws-path", "")
        ws_host = proxy.get("ws-headers", {}).get("Host", "")

        if all([server, port, uuid]):
            params = []
            if tls:
                params.append("security=tls")
            if servername:
                params.append(f"sni={servername}")
            if network:
                params.append(f"type={network}")
            if ws_path:
                params.append(f"path={urllib.parse.quote(ws_path)}")
            if ws_host:
                params.append(f"host={urllib.parse.quote(ws_host)}")

            param_str = "&".join(params)
            safe_name = urllib.parse.quote(p_name)

            link = f"vless://{uuid}@{server}:{port}"
            if param_str:
                link += f"?{param_str}"
            link += f"#{safe_name}"
            return link

    return None

# --- test_clash_meta_nodes å‡½æ•° ---
async def test_clash_meta_nodes(clash_core_path: str, config_path: str, api_port: int = 9090) -> list:
    """
    å¯åŠ¨ Clash.Meta æ ¸å¿ƒï¼ŒåŠ è½½é…ç½®æ–‡ä»¶ï¼Œå¹¶é€šè¿‡å…¶ API æµ‹è¯•æ‰€æœ‰ä»£ç†èŠ‚ç‚¹çš„å»¶è¿Ÿã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«æµ‹è¯•ç»“æœï¼ˆèŠ‚ç‚¹åå’Œå»¶è¿Ÿï¼‰çš„åˆ—è¡¨ã€‚
    """
    clash_process = None
    tested_nodes_info = []
    
    # å¼‚æ­¥å‡½æ•°ï¼šç”¨äºä»StreamReaderä¸­å®æ—¶è¯»å–å¹¶æ‰“å°è¾“å‡º
    async def read_stream_and_print(stream, name):
        while True:
            line = await stream.readline() # å¼‚æ­¥è¯»å–ä¸€è¡Œ
            if not line: # EOF
                break
            print(f"[{name}] {line.decode('utf-8', errors='ignore').strip()}")
        print(f"[{name}] Stream finished.")

    try:
        print(f"\nğŸš€ æ­£åœ¨å¯åŠ¨ Clash.Meta æ ¸å¿ƒè¿›è¡Œæµ‹è¯•...")
        # ä½¿ç”¨ asyncio.create_subprocess_exec æ¥å¯åŠ¨å­è¿›ç¨‹ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ª Process å¯¹è±¡
        # è¿™ä¸ª Process å¯¹è±¡çš„ stdout å’Œ stderr æ˜¯ asyncio.StreamReaderï¼Œå¯ä»¥ç›´æ¥å¼‚æ­¥è¯»å–
        clash_process = await asyncio.create_subprocess_exec(
            clash_core_path,
            "-f", config_path,
            "-d", "./data",
            "-ext-ctl", f"0.0.0.0:{api_port}",
            "-ext-ui", "ui",
            stdout=asyncio.PIPE,
            stderr=asyncio.PIPE
        )
        print(f"Clash.Meta è¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {clash_process.pid}")

        # åˆ›å»ºä»»åŠ¡æ¥å®æ—¶è¯»å– Clash.Meta çš„è¾“å‡º
        stdout_task = asyncio.create_task(read_stream_and_print(clash_process.stdout, "Clash_STDOUT"))
        stderr_task = asyncio.create_task(read_stream_and_print(clash_process.stderr, "Clash_STDERR"))

        # --- ä¼˜åŒ–ç­‰å¾…é€»è¾‘ ---
        api_url_base = f"http://127.0.0.1:{api_port}"
        proxies_api_url = f"{api_url_base}/proxies"
        max_wait_time = 75 # è¿›ä¸€æ­¥å¢åŠ æœ€å¤§ç­‰å¾…ç§’æ•°ï¼Œç»™Clash.Metaæ›´å¤šå¯åŠ¨æ—¶é—´
        wait_interval = 2 # æ¯æ¬¡æ£€æŸ¥é—´éš”ç§’æ•°
        
        print(f"æ­£åœ¨å°è¯•è¿æ¥ Clash.Meta API ({api_url_base})...")
        async with httpx.AsyncClient() as client:
            connected = False
            for i in range(int(max_wait_time / wait_interval)):
                try:
                    response = await client.get(proxies_api_url, timeout=wait_interval)
                    response.raise_for_status()
                    print(f"âœ… æˆåŠŸè¿æ¥åˆ° Clash.Meta API (è€—æ—¶çº¦ {i * wait_interval} ç§’)ã€‚")
                    connected = True
                    break # è¿æ¥æˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                except httpx.RequestError:
                    # æ£€æŸ¥Clashè¿›ç¨‹æ˜¯å¦å·²ç»é€€å‡ºï¼Œå¦‚æœé€€å‡ºåˆ™æ— éœ€ç»§ç»­ç­‰å¾…
                    if clash_process.returncode is not None: # returncode is not None means process has exited
                        print(f"âš ï¸ Clash.Meta è¿›ç¨‹å·²æå‰é€€å‡º (Exit Code: {clash_process.returncode})ï¼Œæ— æ³•è¿æ¥APIã€‚")
                        break
                    print(f"â³ ç­‰å¾… Clash.Meta API ({i * wait_interval + wait_interval}s/{max_wait_time}s)...")
                    await asyncio.sleep(wait_interval)
            
            if not connected:
                print(f"âŒ è¶…è¿‡ {max_wait_time} ç§’æœªè¿æ¥åˆ° Clash.Meta APIï¼Œè·³è¿‡æµ‹è¯•ã€‚")
                return []
        # --- ä¼˜åŒ–ç­‰å¾…é€»è¾‘ç»“æŸ ---

            # è·å–æ‰€æœ‰ä»£ç†åç§°
            all_proxies_data = response.json() # ä½¿ç”¨ä¸Šé¢å·²æˆåŠŸè·å–çš„å“åº”
            proxy_names = []
            for proxy_name, details in all_proxies_data.get("proxies", {}).items():
                # è¿‡æ»¤æ‰Clashçš„å†…ç½®ä»£ç†ç»„ç±»å‹ï¼Œåªä¿ç•™å®é™…çš„ä»£ç†èŠ‚ç‚¹
                if details.get("type") not in ["Fallback", "Selector", "URLTest", "LoadBalance", "Direct", "Reject"]:
                    proxy_names.append(proxy_name)
            print(f"æˆåŠŸè·å–åˆ° {len(proxy_names)} ä¸ªå¯æµ‹è¯•ä»£ç†çš„åç§°ã€‚")
            
            if not proxy_names:
                print("ğŸ¤· æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯æµ‹è¯•çš„ä»£ç†èŠ‚ç‚¹ã€‚")
                return []

            print("\nğŸ”¬ æ­£åœ¨æµ‹è¯•ä»£ç†èŠ‚ç‚¹å»¶è¿Ÿ...")
            tasks = []
            for name in proxy_names:
                # ä½¿ç”¨ http://www.google.com/generate_204 ä½œä¸ºæµ‹è¯•URLï¼Œå› ä¸ºå®ƒè¿”å›ä¸€ä¸ªç©ºå“åº”ï¼Œé€‚åˆæµ‹å»¶è¿Ÿ
                test_url = f"{proxies_api_url}/{urllib.parse.quote(name)}/delay?timeout=5000&url=http://www.google.com/generate_204"
                tasks.append(client.get(test_url, timeout=10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, result in enumerate(results):
                node_name = proxy_names[i]
                if isinstance(result, httpx.Response):
                    try:
                        delay_data = result.json()
                        delay = delay_data.get("delay", -1)
                        if delay > 0: # å»¶è¿Ÿå¤§äº0è¡¨ç¤ºæµ‹è¯•æˆåŠŸ
                            print(f"âœ… {node_name}: {delay}ms")
                            tested_nodes_info.append({"name": node_name, "delay": delay})
                        else:
                            # å»¶è¿Ÿä¸º-1æˆ–å…¶ä»–éæ­£å€¼è¡¨ç¤ºæµ‹è¯•å¤±è´¥æˆ–è¶…æ—¶
                            print(f"ğŸ’” {node_name}: æµ‹è¯•å¤±è´¥/è¶…æ—¶ ({delay_data.get('message', 'æœªçŸ¥é”™è¯¯')})")
                    except json.JSONDecodeError:
                        print(f"ğŸ’” {node_name}: å“åº”è§£æå¤±è´¥")
                elif isinstance(result, httpx.RequestError):
                    print(f"ğŸ’” {node_name}: è¯·æ±‚é”™è¯¯ - {result}")
                else:
                    print(f"ğŸ’” {node_name}: æœªçŸ¥æµ‹è¯•é”™è¯¯ - {result}")

    except Exception as e:
        print(f"âŒ èŠ‚ç‚¹æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        # ç¡®ä¿åœæ­¢ Clash.Meta è¿›ç¨‹ï¼Œå¹¶ç­‰å¾…å…¶è¾“å‡ºä»»åŠ¡å®Œæˆ
        if clash_process and clash_process.returncode is None: # å¦‚æœè¿›ç¨‹ä»åœ¨è¿è¡Œ
            print("ğŸ›‘ æ­£åœ¨åœæ­¢ Clash.Meta è¿›ç¨‹...")
            clash_process.terminate() # å‘é€ç»ˆæ­¢ä¿¡å·
            try:
                await asyncio.wait_for(clash_process.wait(), timeout=5) # å¼‚æ­¥ç­‰å¾…è¿›ç¨‹ç»“æŸ
            except asyncio.TimeoutError:
                clash_process.kill() # å¼ºåˆ¶æ€æ­»è¿›ç¨‹

        # ç¡®ä¿æ—¥å¿—è¯»å–ä»»åŠ¡è¢«å–æ¶ˆå’Œæ¸…ç†
        if stdout_task:
            stdout_task.cancel()
            try:
                await stdout_task
            except asyncio.CancelledError:
                pass
        if stderr_task:
            stderr_task.cancel()
            try:
                await stderr_task
            except asyncio.CancelledError:
                pass

    tested_nodes_info.sort(key=lambda x: x["delay"])
    return tested_nodes_info

# --- main å‡½æ•° ---
async def main():
    print("ğŸš€ å¼€å§‹ä» URL è·å–æ˜æ–‡èŠ‚ç‚¹é“¾æ¥åˆ—è¡¨å¹¶å¤„ç†...")
    all_proxies = []
    all_proxies = await fetch_all_configs(CLASH_BASE_CONFIG_URLS)

    print(f"\nâœ… æ€»å…±ä»é“¾æ¥è§£æåˆ° {len(all_proxies)} ä¸ªä»£ç†èŠ‚ç‚¹ã€‚")

    if not all_proxies:
        print("ğŸ¤· æ²¡æœ‰æ‰¾åˆ°ä»»ä½•èŠ‚ç‚¹ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•å’Œç”Ÿæˆé“¾æ¥ã€‚")
        with open("data/all.txt", "w", encoding="utf-8") as f:
            f.write("")
        return

    unique_proxies_map = {}
    for proxy in all_proxies:
        # ä½¿ç”¨æ›´ä¸¥æ ¼çš„å»é‡æ ‡å‡†ï¼šåç§°ã€ç±»å‹ã€æœåŠ¡å™¨ã€ç«¯å£éƒ½ç›¸åŒæ‰ç®—é‡å¤
        key = (
            proxy.get("name"),
            proxy.get("type"),
            proxy.get("server"),
            proxy.get("port")
        )
        if key not in unique_proxies_map:
             unique_proxies_map[key] = proxy
        else:
             print(f"  â¡ï¸ è·³è¿‡é‡å¤èŠ‚ç‚¹: {proxy.get('name')} ({proxy.get('type')}, {proxy.get('server')}:{proxy.get('port')})")
    
    unique_proxies = list(unique_proxies_map.values())
    print(f"âœ¨ è¿‡æ»¤é‡å¤åå‰©ä½™ {len(unique_proxies)} ä¸ªå”¯ä¸€èŠ‚ç‚¹ã€‚")

    # ç”Ÿæˆç»Ÿä¸€çš„ Clash é…ç½®æ–‡ä»¶
    unified_clash_config = {
        "proxies": unique_proxies,
        "proxy-groups": [
            {
                "name": "Proxy All",
                "type": "select",
                "proxies": [p.get("name") for p in unique_proxies if p.get("name")]
            },
            # å¢åŠ ä¸€ä¸ª URLTest ä»£ç†ç»„ï¼ŒClash.Meta ä¼šè‡ªåŠ¨æµ‹è¯•å…¶ä¸­çš„èŠ‚ç‚¹
            {
                "name": "Auto Select (URLTest)",
                "type": "url-test",
                "proxies": [p.get("name") for p in unique_proxies if p.get("name")],
                "url": "http://www.google.com/generate_204", # æµ‹è¯•URL
                "interval": 300 # æµ‹è¯•é—´éš”ï¼Œå•ä½ç§’ï¼Œè¿™é‡Œè®¾ç½®ä¸º5åˆ†é’Ÿ
            }
        ],
        "rules": [
            "MATCH,Proxy All" # é»˜è®¤è§„åˆ™ï¼Œæ‰€æœ‰æµé‡èµ° Proxy All ç»„
        ],
        "dns": {
            "enable": True,
            "ipv6": False,
            "listen": "0.0.0.0:53",
            "enhanced-mode": True,
            "default-nameserver": [
                "114.114.114.114",
                "8.8.8.8"
            ],
            "nameserver": [
                "tls://dns.google/dns-query",
                "https://dns.alidns.com/dns-query"
            ]
        },
        "log-level": "info",
        "port": 7890, # HTTPä»£ç†ç«¯å£
        "socks-port": 7891, # SOCKSä»£ç†ç«¯å£
        "mode": "rule",
        "allow-lan": True, # å…è®¸å±€åŸŸç½‘è®¿é—®ï¼Œæ–¹ä¾¿APIè°ƒç”¨
        "external-controller": "0.0.0.0:9090", # å¤–éƒ¨æ§åˆ¶APIç«¯å£
        "external-ui": "ui" # å¦‚æœæœ‰UIæ–‡ä»¶ï¼Œå¯ä»¥æŒ‡å®š
    }

    unified_config_path = "data/unified_clash_config.yaml"
    try:
        with open(unified_config_path, "w", encoding="utf-8") as f:
            yaml.dump(unified_clash_config, f, allow_unicode=True, sort_keys=False)
        print(f"ğŸ“¦ ç»Ÿä¸€çš„ Clash é…ç½®æ–‡ä»¶å·²ç”Ÿæˆï¼š{unified_config_path}")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šç”Ÿæˆç»Ÿä¸€ Clash é…ç½®æ–‡ä»¶å¤±è´¥ï¼š{e}")

    # æ£€æŸ¥ CLASH_CORE_PATH ç¯å¢ƒå˜é‡æ˜¯å¦å­˜åœ¨
    clash_core_path = os.environ.get("CLASH_CORE_PATH")
    if not clash_core_path:
        print("âŒ é”™è¯¯ï¼šç¯å¢ƒå˜é‡ CLASH_CORE_PATH æœªè®¾ç½®ï¼Œæ— æ³•æ‰§è¡Œ Clash.Meta æµ‹è¯•ã€‚")
        # å³ä½¿æ— æ³•æµ‹è¯•ï¼Œä¹Ÿè¦å°è¯•ç”ŸæˆåŸå§‹æ˜æ–‡é“¾æ¥ï¼Œä»¥é˜²ä¸‡ä¸€
        output_file_path = "data/all.txt"
        with open(output_file_path, "w", encoding="utf-8") as f:
            for link in [generate_plaintext_node_link(node) for node in unique_proxies if generate_plaintext_node_link(node)]:
                f.write(link + "\n")
        print(f"â¡ï¸ ä»…ç”Ÿæˆæ˜æ–‡é“¾æ¥åˆ°ï¼š{output_file_path}")
        print(f"æ€»å…±ç”Ÿæˆ {len(unique_proxies)} æ¡æ˜æ–‡é“¾æ¥ã€‚")
        return # æå‰é€€å‡ºï¼Œä¸å†å°è¯•è¿›è¡ŒClashæµ‹è¯•

    print("\n--- å¼€å§‹ä½¿ç”¨ Clash.Meta è¿›è¡ŒèŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯• ---")
    tested_nodes = await test_clash_meta_nodes(clash_core_path, unified_config_path)

    # æ ¹æ®æµ‹è¯•ç»“æœç”Ÿæˆæœ€ç»ˆçš„æ˜æ–‡é“¾æ¥åˆ—è¡¨
    final_output_links = []
    if tested_nodes:
        print("\n--- å»¶è¿Ÿæµ‹è¯•ç»“æœ (æŒ‰å»¶è¿Ÿå‡åº) ---")
        for node_info in tested_nodes:
            # æ‰¾åˆ°åŸå§‹çš„ä»£ç†å¯¹è±¡æ¥ç”Ÿæˆæ˜æ–‡é“¾æ¥
            original_node = next((p for p in unique_proxies if p.get("name") == node_info["name"]), None)
            if original_node:
                link = generate_plaintext_node_link(original_node)
                if link:
                    # å°†å»¶è¿Ÿä¿¡æ¯æ·»åŠ åˆ°é“¾æ¥åé¢
                    final_output_links.append(f"{link} # {node_info['delay']}ms")
                    print(f"{node_info['name']}: {node_info['delay']}ms -> {link}")
                else:
                    print(f"{node_info['name']}: {node_info['delay']}ms -> æ— æ³•ç”Ÿæˆæ˜æ–‡é“¾æ¥")
            else:
                print(f"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°åŸå§‹èŠ‚ç‚¹ä¿¡æ¯ '{node_info['name']}'")
    else:
        print("\nğŸ˜” æ²¡æœ‰èŠ‚ç‚¹é€šè¿‡å»¶è¿Ÿæµ‹è¯•ã€‚")
        # å¦‚æœæ²¡æœ‰èŠ‚ç‚¹é€šè¿‡æµ‹è¯•ï¼Œä»ç„¶è¾“å‡ºåŸå§‹çš„æ˜æ–‡é“¾æ¥ï¼ˆä¸å¸¦å»¶è¿Ÿä¿¡æ¯ï¼‰
        # é¿å… data/all.txt ä¸ºç©ºå¯¼è‡´åç»­çš„ git commit è­¦å‘Šæˆ–å¤±è´¥
        final_output_links = [generate_plaintext_node_link(node) for node in unique_proxies if generate_plaintext_node_link(node)]


    # å°†æœ€ç»ˆçš„æµ‹è¯•ç»“æœå†™å…¥ data/all.txt
    output_file_path = "data/all.txt"
    with open(output_file_path, "w", encoding="utf-8") as f:
        for link in final_output_links:
            f.write(link + "\n")
    print(f"\nâœ… æœ€ç»ˆçš„æµ‹è¯•ç»“æœå’Œæ˜æ–‡é“¾æ¥å·²å†™å…¥ï¼š{output_file_path}")
    print(f"æ€»å…±è¾“å‡º {len(final_output_links)} æ¡ç»“æœã€‚")


if __name__ == "__main__":
    # ç¡®ä¿å®‰è£…äº† httpx å’Œ PyYAML
    # Clash.Meta æ ¸å¿ƒè·¯å¾„ç”± GitHub Actions ç¯å¢ƒå˜é‡æä¾›
    asyncio.run(main())
