import httpx
import yaml
import asyncio
import base64
import json
import os
import urllib.parse
import subprocess # ç”¨äºå¯åŠ¨Clash.Metaè¿›ç¨‹
import time # ç”¨äºç­‰å¾…Clash.Metaå¯åŠ¨

# ... (CLASH_BASE_CONFIG_URLS, fetch_and_parse_clash_config, generate_plaintext_node_link ä¿æŒä¸å˜) ...

# --- æ–°å¢ï¼šä½¿ç”¨ Clash.Meta API è¿›è¡ŒèŠ‚ç‚¹æµ‹è¯•çš„å‡½æ•° ---
async def test_clash_meta_nodes(clash_core_path: str, config_path: str, api_port: int = 9090) -> list:
    """
    å¯åŠ¨ Clash.Meta æ ¸å¿ƒï¼ŒåŠ è½½é…ç½®æ–‡ä»¶ï¼Œå¹¶é€šè¿‡å…¶ API æµ‹è¯•æ‰€æœ‰ä»£ç†èŠ‚ç‚¹çš„å»¶è¿Ÿã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«æµ‹è¯•ç»“æœï¼ˆèŠ‚ç‚¹åå’Œå»¶è¿Ÿï¼‰çš„åˆ—è¡¨ã€‚
    """
    clash_process = None
    tested_nodes_info = [] # å­˜å‚¨æµ‹è¯•æˆåŠŸçš„èŠ‚ç‚¹ä¿¡æ¯ {name: ..., delay: ..., link: ...}

    try:
        print(f"\nğŸš€ æ­£åœ¨å¯åŠ¨ Clash.Meta æ ¸å¿ƒè¿›è¡Œæµ‹è¯•...")
        # å¯åŠ¨ Clash.Meta è¿›ç¨‹ï¼ŒåŠ è½½æŒ‡å®šçš„é…ç½®æ–‡ä»¶
        # -f æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œ-d æŒ‡å®šå·¥ä½œç›®å½•ï¼ˆæ—¥å¿—ã€ç¼“å­˜ç­‰ï¼‰
        # 'data' ç›®å½•å·²åœ¨ GitHub Actions ä¸­åˆ›å»º
        clash_process = subprocess.Popen(
            [clash_core_path, "-f", config_path, "-d", "./data", "-ext-ctl", f"0.0.0.0:{api_port}", "-ext-ui", "ui"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
            # æ³¨æ„ï¼šåœ¨GitHub Actionsä¸­ï¼Œstdoutå’Œstderrå¯ä»¥é‡å®šå‘åˆ°/dev/nullä»¥å‡å°‘æ—¥å¿—ï¼Œ
            # ä½†è¿™é‡Œæˆ‘ä»¬æš‚æ—¶ä¿ç•™ï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚
        )
        print(f"Clash.Meta è¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {clash_process.pid}")

        # ç­‰å¾… Clash.Meta å®Œå…¨å¯åŠ¨å¹¶ç›‘å¬ API ç«¯å£
        # è¿™ä¸ªç­‰å¾…æ—¶é—´å¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        print(f"ç­‰å¾… Clash.Meta å¯åŠ¨å¹¶ç›‘å¬ {api_port} ç«¯å£...")
        await asyncio.sleep(5) # ç»™5ç§’é’Ÿè®©Clash.Metaå¯åŠ¨

        api_url_base = f"http://127.0.0.1:{api_port}"
        proxies_api_url = f"{api_url_base}/proxies"

        async with httpx.AsyncClient() as client:
            # 1. è·å–æ‰€æœ‰ä»£ç†åç§°
            retries = 3
            proxy_names = []
            for attempt in range(retries):
                try:
                    response = await client.get(proxies_api_url, timeout=5)
                    response.raise_for_status()
                    all_proxies_data = response.json()
                    
                    # æå–æ‰€æœ‰å¯æµ‹è¯•çš„ä»£ç†åç§°
                    for proxy_name, details in all_proxies_data.get("proxies", {}).items():
                        if details.get("type") not in ["Fallback", "Selector", "URLTest", "LoadBalance"]:
                            proxy_names.append(proxy_name)
                    print(f"æˆåŠŸè·å–åˆ° {len(proxy_names)} ä¸ªå¯æµ‹è¯•ä»£ç†çš„åç§°ã€‚")
                    break
                except (httpx.RequestError, json.JSONDecodeError) as e:
                    print(f"âŒ å°è¯• {attempt+1}/{retries} è®¿é—® Clash API å¤±è´¥: {e}")
                    await asyncio.sleep(2) # ç­‰å¾…åé‡è¯•
            else:
                print("âŒ æ— æ³•ä» Clash.Meta API è·å–ä»£ç†åˆ—è¡¨ï¼Œè·³è¿‡æµ‹è¯•ã€‚")
                return []
            
            if not proxy_names:
                print("ğŸ¤· æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯æµ‹è¯•çš„ä»£ç†èŠ‚ç‚¹ã€‚")
                return []

            # 2. é€ä¸ªæµ‹è¯•ä»£ç†å»¶è¿Ÿ
            print("\nğŸ”¬ æ­£åœ¨æµ‹è¯•ä»£ç†èŠ‚ç‚¹å»¶è¿Ÿ...")
            tasks = []
            for name in proxy_names:
                # è§¦å‘å»¶è¿Ÿæµ‹è¯•çš„API endpoint
                test_url = f"{proxies_api_url}/{urllib.parse.quote(name)}/delay?timeout=5000&url=http://www.google.com/generate_204"
                tasks.append(client.get(test_url, timeout=10)) # æ¯ä¸ªæµ‹è¯•è¯·æ±‚10ç§’è¶…æ—¶

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, result in enumerate(results):
                node_name = proxy_names[i]
                if isinstance(result, httpx.Response):
                    try:
                        delay_data = result.json()
                        delay = delay_data.get("delay", -1)
                        if delay > 0:
                            print(f"âœ… {node_name}: {delay}ms")
                            tested_nodes_info.append({"name": node_name, "delay": delay})
                        else:
                            print(f"ğŸ’” {node_name}: æµ‹è¯•å¤±è´¥/è¶…æ—¶ ({delay_data.get('message', 'æœªçŸ¥é”™è¯¯')})")
                    except json.JSONDecodeError:
                        print(f"ğŸ’” {node_name}: å“åº”è§£æå¤±è´¥")
                elif isinstance(result, httpx.RequestError):
                    print(f"ğŸ’” {node_name}: è¯·æ±‚é”™è¯¯ - {result}")
                else:
                    print(f"ğŸ’” {node_name}: æœªçŸ¥æµ‹è¯•é”™è¯¯ - {result}")

    except Exception as e:
        print(f"âŒ èŠ‚ç‚¹æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        if clash_process and clash_process.poll() is None: # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
            print("ğŸ›‘ æ­£åœ¨åœæ­¢ Clash.Meta è¿›ç¨‹...")
            clash_process.terminate() # å°è¯•ç»ˆæ­¢è¿›ç¨‹
            try:
                clash_process.wait(timeout=5) # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            except subprocess.TimeoutExpired:
                clash_process.kill() # å¦‚æœæ²¡ç»“æŸï¼Œå¼ºåˆ¶æ€æ­»

    # å¯¹æµ‹è¯•æˆåŠŸçš„èŠ‚ç‚¹æŒ‰å»¶è¿Ÿæ’åº
    tested_nodes_info.sort(key=lambda x: x["delay"])
    return tested_nodes_info

# ... (main å‡½æ•°çš„å®šä¹‰) ...
async def main():
    print("ğŸš€ å¼€å§‹ä» URL è·å–æ˜æ–‡èŠ‚ç‚¹é“¾æ¥åˆ—è¡¨å¹¶å¤„ç†...")
    all_proxies = []
    all_proxies = await fetch_all_configs(CLASH_BASE_CONFIG_URLS)

    print(f"\nâœ… æ€»å…±ä»é“¾æ¥è§£æåˆ° {len(all_proxies)} ä¸ªä»£ç†èŠ‚ç‚¹ã€‚")

    if not all_proxies:
        print("ğŸ¤· æ²¡æœ‰æ‰¾åˆ°ä»»ä½•èŠ‚ç‚¹ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•å’Œç”Ÿæˆé“¾æ¥ã€‚")
        # å³ä½¿æ²¡æœ‰èŠ‚ç‚¹ï¼Œä¹Ÿåˆ›å»ºä¸€ä¸ªç©ºçš„ all.txt é˜²æ­¢åç»­æ­¥éª¤æŠ¥é”™
        with open("data/all.txt", "w", encoding="utf-8") as f:
            f.write("")
        return

    # è¿‡æ»¤æ‰é‡å¤çš„èŠ‚ç‚¹
    unique_proxies_map = {}
    for proxy in all_proxies:
        key = (
            proxy.get("name"),
            proxy.get("type"),
            proxy.get("server"),
            proxy.get("port")
        )
        if key not in unique_proxies_map:
             unique_proxies_map[key] = proxy
        else:
             print(f"  â¡ï¸ è·³è¿‡é‡å¤èŠ‚ç‚¹: {proxy.get('name')} ({proxy.get('type')})")
    
    unique_proxies = list(unique_proxies_map.values())
    print(f"âœ¨ è¿‡æ»¤é‡å¤åå‰©ä½™ {len(unique_proxies)} ä¸ªå”¯ä¸€èŠ‚ç‚¹ã€‚")

    # ç”Ÿæˆç»Ÿä¸€çš„ Clash é…ç½®
    unified_clash_config = {
        "proxies": unique_proxies,
        "proxy-groups": [
            {
                "name": "Proxy All",
                "type": "select",
                "proxies": [p.get("name") for p in unique_proxies if p.get("name")]
            },
            # å¢åŠ ä¸€ä¸ª URLTest ä»£ç†ç»„ï¼ŒClash.Meta ä¼šè‡ªåŠ¨æµ‹è¯•å…¶ä¸­çš„èŠ‚ç‚¹
            {
                "name": "Auto Select (URLTest)",
                "type": "url-test",
                "proxies": [p.get("name") for p in unique_proxies if p.get("name")],
                "url": "http://www.google.com/generate_204", # æµ‹è¯•URL
                "interval": 300 # æµ‹è¯•é—´éš”ï¼Œå•ä½ç§’ï¼Œè¿™é‡Œè®¾ç½®ä¸º5åˆ†é’Ÿ
            }
        ],
        "rules": [
            "MATCH,Proxy All" # é»˜è®¤è§„åˆ™ï¼Œæ‰€æœ‰æµé‡èµ° Proxy All ç»„
        ],
        "dns": {
            "enable": True,
            "ipv6": False,
            "listen": "0.0.0.0:53",
            "enhanced-mode": True,
            "default-nameserver": [
                "114.114.114.114",
                "8.8.8.8"
            ],
            "nameserver": [
                "tls://dns.google/dns-query",
                "https://dns.alidns.com/dns-query"
            ]
        },
        "log-level": "info",
        "port": 7890, # HTTPä»£ç†ç«¯å£
        "socks-port": 7891, # SOCKSä»£ç†ç«¯å£
        "mode": "rule",
        "allow-lan": True, # å…è®¸å±€åŸŸç½‘è®¿é—®ï¼Œæ–¹ä¾¿APIè°ƒç”¨
        "external-controller": "0.0.0.0:9090", # å¤–éƒ¨æ§åˆ¶APIç«¯å£
        "external-ui": "ui" # å¦‚æœæœ‰UIæ–‡ä»¶ï¼Œå¯ä»¥æŒ‡å®š
    }

    unified_config_path = "data/unified_clash_config.yaml"
    try:
        with open(unified_config_path, "w", encoding="utf-8") as f:
            yaml.dump(unified_clash_config, f, allow_unicode=True, sort_keys=False)
        print(f"ğŸ“¦ ç»Ÿä¸€çš„ Clash é…ç½®æ–‡ä»¶å·²ç”Ÿæˆï¼š{unified_config_path}")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šç”Ÿæˆç»Ÿä¸€ Clash é…ç½®æ–‡ä»¶å¤±è´¥ï¼š{e}")

    # --- å®é™…æ‰§è¡ŒèŠ‚ç‚¹æµ‹è¯• ---
    clash_core_path = os.environ.get("CLASH_CORE_PATH")
    if not clash_core_path:
        print("âŒ é”™è¯¯ï¼šç¯å¢ƒå˜é‡ CLASH_CORE_PATH æœªè®¾ç½®ï¼Œæ— æ³•æ‰§è¡Œ Clash.Meta æµ‹è¯•ã€‚")
        # æ­¤æ—¶ä»ç„¶å°è¯•è¾“å‡ºall.txtï¼Œä½†æµ‹è¯•åŠŸèƒ½ç¼ºå¤±
        output_file_path = "data/all.txt"
        with open(output_file_path, "w", encoding="utf-8") as f:
            for link in [generate_plaintext_node_link(node) for node in unique_proxies if generate_plaintext_node_link(node)]:
                f.write(link + "\n")
        print(f"â¡ï¸ ä»…ç”Ÿæˆæ˜æ–‡é“¾æ¥åˆ°ï¼š{output_file_path}")
        print(f"æ€»å…±ç”Ÿæˆ {len(plaintext_links)} æ¡æ˜æ–‡é“¾æ¥ã€‚")
        return # æå‰é€€å‡º

    print("\n--- å¼€å§‹ä½¿ç”¨ Clash.Meta è¿›è¡ŒèŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯• ---")
    tested_nodes = await test_clash_meta_nodes(clash_core_path, unified_config_path)

    # æ ¹æ®æµ‹è¯•ç»“æœç”Ÿæˆæœ€ç»ˆçš„æ˜æ–‡é“¾æ¥åˆ—è¡¨
    final_output_links = []
    if tested_nodes:
        print("\n--- å»¶è¿Ÿæµ‹è¯•ç»“æœ (æŒ‰å»¶è¿Ÿå‡åº) ---")
        for node_info in tested_nodes:
            # æ‰¾åˆ°åŸå§‹çš„ä»£ç†å¯¹è±¡æ¥ç”Ÿæˆæ˜æ–‡é“¾æ¥
            original_node = next((p for p in unique_proxies if p.get("name") == node_info["name"]), None)
            if original_node:
                link = generate_plaintext_node_link(original_node)
                if link:
                    final_output_links.append(f"{link} # {node_info['delay']}ms")
                    print(f"{node_info['name']}: {node_info['delay']}ms -> {link}")
                else:
                    print(f"{node_info['name']}: {node_info['delay']}ms -> æ— æ³•ç”Ÿæˆæ˜æ–‡é“¾æ¥")
            else:
                print(f"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°åŸå§‹èŠ‚ç‚¹ä¿¡æ¯ '{node_info['name']}'")
    else:
        print("\nğŸ˜” æ²¡æœ‰èŠ‚ç‚¹é€šè¿‡å»¶è¿Ÿæµ‹è¯•ã€‚")
        # å¦‚æœæ²¡æœ‰èŠ‚ç‚¹é€šè¿‡æµ‹è¯•ï¼Œä»ç„¶è¾“å‡ºåŸå§‹çš„æ˜æ–‡é“¾æ¥ï¼ˆä¸å¸¦å»¶è¿Ÿä¿¡æ¯ï¼‰
        final_output_links = [generate_plaintext_node_link(node) for node in unique_proxies if generate_plaintext_node_link(node)]


    # å°†æœ€ç»ˆçš„æµ‹è¯•ç»“æœå†™å…¥ data/all.txt
    output_file_path = "data/all.txt"
    with open(output_file_path, "w", encoding="utf-8") as f:
        for link in final_output_links:
            f.write(link + "\n")
    print(f"\nâœ… æœ€ç»ˆçš„æµ‹è¯•ç»“æœå’Œæ˜æ–‡é“¾æ¥å·²å†™å…¥ï¼š{output_file_path}")
    print(f"æ€»å…±è¾“å‡º {len(final_output_links)} æ¡ç»“æœã€‚")


if __name__ == "__main__":
    # ç¡®ä¿å®‰è£…äº† httpx å’Œ PyYAML
    # Clash.Meta æ ¸å¿ƒè·¯å¾„ç”± GitHub Actions ç¯å¢ƒå˜é‡æä¾›
    asyncio.run(main())
