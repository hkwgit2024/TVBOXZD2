import asyncio
import aiohttp
import base64
import json
import logging
import re
import urllib.parse
import yaml
import os
import argparse
import uuid # ç”¨äº VMess é»˜è®¤ UUIDï¼Œè™½ç„¶å®é™…èŠ‚ç‚¹ä¼šæœ‰è‡ªå·±çš„ UUID
from collections import defaultdict
from typing import List, Dict, Set, Optional
from datetime import datetime

# é…ç½®æ—¥å¿—ç³»ç»Ÿï¼Œå°†æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
logging.basicConfig(
    level=logging.INFO, # é»˜è®¤æ—¥å¿—çº§åˆ«ä¸º INFO
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('proxy_converter.log', encoding='utf-8'), # æ—¥å¿—æ–‡ä»¶ï¼Œç¡®ä¿æ”¯æŒä¸­æ–‡
        logging.StreamHandler() # æ§åˆ¶å°è¾“å‡º
    ]
)
logger = logging.getLogger(__name__)

# å®šä¹‰æ”¯æŒçš„èŠ‚ç‚¹åè®®åŠå…¶æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
NODE_PATTERNS = {
    'ss': r'ss://[^\s#]+(?:#[^\n]*)?',
    'vmess': r'vmess://[^\s]+',
    'trojan': r'trojan://[^\s#]+(?:#[^\n]*)?',
    'vless': r'vless://[^\s#]+(?:#[^\n]*)?',
    'hysteria2': r'hysteria2://[^\s#]+(?:#[^\n]*)?',
    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å…¶ä»–åè®®çš„æ¨¡å¼ï¼Œä¾‹å¦‚ WireGuard, Tuic ç­‰
}
# ç»„åˆæ‰€æœ‰åè®®æ¨¡å¼ï¼Œç”¨äºåœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾
COMBINED_REGEX_PATTERN = "|".join(NODE_PATTERNS.values())

def setup_argparse() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚"""
    parser = argparse.ArgumentParser(description='ä»£ç†èŠ‚ç‚¹æå–å’Œè½¬æ¢å·¥å…·')
    parser.add_argument('--sources', default='sources.list', help='åŒ…å«æº URL çš„è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', default='data/nodes.txt', help='æå–åˆ°çš„èŠ‚ç‚¹è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--clash-output', default='data/clash.yaml', help='Clash YAML é…ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-concurrency', type=int, default=50, help='æœ€å¤§å¹¶å‘è¯·æ±‚æ•°')
    parser.add_argument('--timeout', type=int, default=20, help='è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    return parser.parse_args()

def decode_base64(data: str) -> str:
    """è§£ç  Base64 å­—ç¬¦ä¸²ï¼Œå¹¶ä¿®å¤å¯èƒ½å­˜åœ¨çš„å¡«å……é—®é¢˜ã€‚"""
    try:
        # ç§»é™¤ç©ºç™½ç¬¦ï¼Œå¹¶æ›¿æ¢ URL å®‰å…¨çš„å­—ç¬¦
        data = data.strip().replace('-', '+').replace('_', '/')
        # æ·»åŠ  Base64 å¡«å……ç¬¦
        padding = len(data) % 4
        if padding:
            data += '=' * (4 - padding)
        return base64.b64decode(data).decode('utf-8', errors='ignore')
    except Exception as e:
        logger.debug(f"Base64 è§£ç é”™è¯¯: {e}")
        return ""

def encode_base64(data: str) -> str:
    """ç¼–ç å­—ç¬¦ä¸²ä¸º URL å®‰å…¨çš„ Base64 æ ¼å¼ã€‚"""
    encoded_bytes = base64.urlsafe_b64encode(data.encode('utf-8'))
    return encoded_bytes.decode('utf-8').rstrip('=')

def convert_clash_proxy_to_url(proxy: Dict) -> Optional[str]:
    """
    å°† Clash ä»£ç†é…ç½®å­—å…¸è½¬æ¢ä¸ºæ ‡å‡† URL æ ¼å¼ã€‚
    è¿™æ˜¯ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼Œéœ€è¦å°½å¯èƒ½ç²¾ç¡®åœ°æ˜ å°„ Clash é…ç½®åˆ°æ ‡å‡† URL å‚æ•°ã€‚
    å¦‚æœè½¬æ¢å¤±è´¥æˆ–ä¸æ”¯æŒè¯¥ç±»å‹ï¼Œåˆ™è¿”å› Noneã€‚
    """
    proxy_type = proxy.get('type', '').lower()
    # èŠ‚ç‚¹åç§°ï¼Œç¡®ä¿è¿›è¡Œ URL ç¼–ç 
    name = urllib.parse.quote(proxy.get('name', f"{proxy_type}_node").strip(), safe='')

    server = proxy.get('server')
    port = proxy.get('port')
    
    if not all([server, port, proxy_type]): # æ£€æŸ¥å¿…éœ€çš„æ ¸å¿ƒä¿¡æ¯
        logger.debug(f"ç¼ºå°‘ Clash ä»£ç† {name} çš„æ ¸å¿ƒä¿¡æ¯: {proxy}")
        return None

    if proxy_type == 'ss':
        cipher = proxy.get('cipher')
        password = proxy.get('password')
        plugin = proxy.get('plugin')
        plugin_opts = proxy.get('plugin-opts', {})

        if not all([cipher, password]):
            logger.debug(f"SS ä»£ç† {name} ç¼ºå°‘åŠ å¯†æ–¹æ³•æˆ–å¯†ç : {proxy}")
            return None

        # SS è®¤è¯ä¿¡æ¯ï¼šmethod:password
        auth = encode_base64(f"{cipher}:{password}")
        
        params = []
        if plugin:
            # SS æ’ä»¶å¤„ç†ï¼Œæ ¹æ®å¸¸è§æ’ä»¶å’Œå…¶å‚æ•°è¿›è¡Œæ˜ å°„
            if plugin == 'obfs' and 'mode' in plugin_opts:
                params.append(f"plugin={plugin}")
                params.append(f"obfs-host={urllib.parse.quote(plugin_opts.get('host', ''))}")
                params.append(f"obfs-mode={plugin_opts['mode']}")
            elif plugin == 'v2ray-plugin': # V2ray-plugin å…¼å®¹æ€§å¤„ç†
                params.append(f"plugin={plugin}")
                params.append(f"v2ray-plugin-mode={plugin_opts.get('mode', 'websocket')}")
                params.append(f"v2ray-plugin-host={urllib.parse.quote(plugin_opts.get('host', ''))}")
                params.append(f"v2ray-plugin-path={urllib.parse.quote(plugin_opts.get('path', ''))}")
                if plugin_opts.get('tls'): params.append("v2ray-plugin-tls=true")
                if plugin_opts.get('skip-cert-verify'): params.append("v2ray-plugin-skip-cert-verify=true")
                if plugin_opts.get('mux'): params.append("v2ray-plugin-mux=true")
            # å…¶ä»– SS æ’ä»¶ç±»å‹å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        
        query_string = "?" + "&".join(params) if params else ""
        return f"ss://{auth}@{server}:{port}{query_string}#{name}"

    elif proxy_type == 'vmess':
        uuid_val = proxy.get('uuid')
        network = proxy.get('network', 'tcp')
        tls_enabled = proxy.get('tls', False)
        
        if not uuid_val:
            logger.debug(f"VMess ä»£ç† {name} ç¼ºå°‘ UUID: {proxy}")
            return None

        config = {
            "v": "2",
            "ps": urllib.parse.unquote(name), # VMess JSON ä¸­çš„åç§°ä¸åº” URL ç¼–ç 
            "add": server,
            "port": port,
            "id": uuid_val,
            "aid": proxy.get('alterId', 0),
            "net": network,
            "type": proxy.get('cipher', 'auto'), # Clash çš„ type å­—æ®µæœ‰æ—¶æ˜ å°„åˆ° VMess çš„åŠ å¯†æ–¹å¼
        }
        
        # TLS ç›¸å…³é€‰é¡¹
        if tls_enabled:
            config["tls"] = "tls"
            sni = proxy.get('servername') or proxy.get('host')
            if sni:
                config["host"] = sni # VMess JSON ä¸­çš„ host å­—æ®µé€šå¸¸ç”¨äº SNI/Host header
                config["sni"] = sni
            
            if proxy.get('skip-cert-verify'):
                config["allowInsecure"] = 1
            if proxy.get('alpn'):
                config["alpn"] = ",".join(proxy['alpn'])
            if proxy.get('client-fingerprint'):
                config["fp"] = proxy['client-fingerprint']

        # ç½‘ç»œä¼ è¾“æ–¹å¼ç‰¹å®šé€‰é¡¹
        if network == 'ws':
            ws_opts = proxy.get('ws-opts', {})
            config["path"] = ws_opts.get('path', '/')
            if 'headers' in ws_opts and 'Host' in ws_opts['headers']:
                config['host'] = ws_opts['headers']['Host']
            elif 'host' in ws_opts:
                config['host'] = ws_opts['host']
            if ws_opts.get('max-early-data'): config['maxEarlyData'] = ws_opts['max-early-data']
            if ws_opts.get('early-data-header'): config['earlyDataHeader'] = ws_opts['early-data-header']
            
        elif network == 'grpc':
            grpc_opts = proxy.get('grpc-opts', {})
            config["serviceName"] = grpc_opts.get('grpc-service-name', '')
            if grpc_opts.get('mode'): config["mode"] = grpc_opts['mode'] # gun/multi-mode
            
        elif network == 'http':
            http_opts = proxy.get('http-opts', {})
            if http_opts.get('method'):
                config['method'] = http_opts['method']
            if http_opts.get('headers'):
                for header_key, header_value in http_opts['headers'].items():
                    if header_key.lower() == 'host':
                        config['host'] = header_value[0] if isinstance(header_value, list) else header_value
                        break
        
        # æ¸…ç†ç©ºå€¼å’Œ None å€¼ï¼Œç¡®ä¿ JSON ç®€æ´æœ‰æ•ˆ
        clean_config = {k: v for k, v in config.items() if v is not None and v != ''}
        # ç¡®ä¿ 'ps' (èŠ‚ç‚¹åç§°) å­˜åœ¨ä¸”ä¸ä¸ºç©º
        if not clean_config.get('ps'):
            clean_config['ps'] = urllib.parse.unquote(name)
        
        try:
            return f"vmess://{encode_base64(json.dumps(clean_config, ensure_ascii=False))}"
        except Exception as e:
            logger.debug(f"VMess é…ç½® JSON ç¼–ç å¤±è´¥ï¼ŒèŠ‚ç‚¹ï¼š{name}ã€‚é”™è¯¯ï¼š{e}")
            return None

    elif proxy_type == 'trojan':
        password = proxy.get('password')
        tls_enabled = proxy.get('tls', False) # Trojan é€šå¸¸éœ€è¦ TLS
        
        if not all([password, tls_enabled]):
            logger.debug(f"Trojan ä»£ç† {name} ç¼ºå°‘å¯†ç æˆ–æœªå¯ç”¨ TLS: {proxy}")
            return None
        
        params = []
        # SNI ä¼˜å…ˆä½¿ç”¨ 'servername'ï¼Œå…¶æ¬¡ 'host'ï¼Œæœ€åæ˜¯ 'server'
        sni = proxy.get('servername') or proxy.get('host') or server
        if sni: params.append(f"sni={urllib.parse.quote(sni)}")
        
        if proxy.get('alpn'): params.append(f"alpn={urllib.parse.quote(','.join(proxy['alpn']))}")
        if proxy.get('client-fingerprint'): params.append(f"fp={urllib.parse.quote(proxy['client-fingerprint'])}")
        if proxy.get('skip-cert-verify'): params.append("allowInsecure=1") # Trojan URL ä¸­ä¸º allowInsecure
        if proxy.get('udp', True): params.append("udp=true") # é»˜è®¤ UDP æ”¯æŒ

        # ç½‘ç»œä¼ è¾“æ–¹å¼é€‰é¡¹ (ä¾‹å¦‚ WebSocket, gRPC)ï¼ŒTrojan URL ä¸­ä¹Ÿé€šè¿‡æŸ¥è¯¢å‚æ•°ä½“ç°
        network = proxy.get('network')
        if network == 'ws':
            ws_opts = proxy.get('ws-opts', {})
            params.append(f"type=ws")
            params.append(f"path={urllib.parse.quote(ws_opts.get('path', '/'))}")
            if 'headers' in ws_opts and 'host' in ws_opts['headers']:
                params.append(f"host={urllib.parse.quote(ws_opts['headers']['host'])}")
            elif 'host' in ws_opts:
                params.append(f"host={urllib.parse.quote(ws_opts['host'])}")
        elif network == 'grpc':
            grpc_opts = proxy.get('grpc-opts', {})
            params.append(f"type=grpc")
            params.append(f"serviceName={urllib.parse.quote(grpc_opts.get('grpc-service-name', ''))}")
            if grpc_opts.get('mode'): params.append(f"mode={urllib.parse.quote(grpc_opts['mode'])}")
            
        query_string = "?" + "&".join(params) if params else ""
        return f"trojan://{password}@{server}:{port}{query_string}#{name}"

    elif proxy_type == 'vless':
        uuid_val = proxy.get('uuid')
        network = proxy.get('network', 'tcp')
        tls_enabled = proxy.get('tls', False)
        
        if not uuid_val:
            logger.debug(f"VLESS ä»£ç† {name} ç¼ºå°‘ UUID: {proxy}")
            return None
        
        params = {
            "type": network # ç½‘ç»œä¼ è¾“ç±»å‹æ˜¯ VLESS å¿…éœ€å‚æ•°
        }
        
        # TLS ç›¸å…³é€‰é¡¹
        if tls_enabled:
            params['security'] = 'tls'
            sni = proxy.get('servername') or proxy.get('host') or server
            if sni: params['sni'] = sni
            
            if proxy.get('alpn'): params['alpn'] = ",".join(proxy['alpn'])
            if proxy.get('client-fingerprint'): params['fp'] = proxy['client-fingerprint']
            if proxy.get('skip-cert-verify'): params['allowInsecure'] = '1'
            if proxy.get('flow'): params['flow'] = proxy['flow'] # VLESS flow

        # ç½‘ç»œä¼ è¾“æ–¹å¼ç‰¹å®šé€‰é¡¹
        if network == 'ws':
            ws_opts = proxy.get('ws-opts', {})
            params['path'] = ws_opts.get('path', '/')
            if 'headers' in ws_opts and 'host' in ws_opts['headers']:
                params['host'] = ws_opts['headers']['host']
            elif 'host' in ws_opts:
                params['host'] = ws_opts['host']

        elif network == 'grpc':
            grpc_opts = proxy.get('grpc-opts', {})
            params['serviceName'] = grpc_opts.get('grpc-service-name', '')
            if grpc_opts.get('mode'): params['mode'] = grpc_opts['mode']
            
        query_string = urllib.parse.urlencode(params, quote_via=urllib.parse.quote)
        return f"vless://{uuid_val}@{server}:{port}?{query_string}#{name}"

    elif proxy_type == 'hysteria2':
        password = proxy.get('password', '')
        server = proxy.get('server', '')
        port = proxy.get('port', 0)
        
        if not (password and server and port):
            logger.debug(f"Hysteria2 ä»£ç† {name} ç¼ºå°‘å¯†ç ã€æœåŠ¡å™¨æˆ–ç«¯å£: {proxy}")
            return None

        params = []
        if proxy.get('sni'):
            params.append(f"sni={urllib.parse.quote(proxy['sni'])}")
        if proxy.get('skip-cert-verify', False):
            params.append("insecure=1") # Hysteria2 URL ä¸­ä¸º insecure
        if proxy.get('fast-open', False):
            params.append("fastopen=1")
        if proxy.get('up', 0): # ä¸Šè¡Œå¸¦å®½
            params.append(f"up_mbps={proxy['up']}")
        if proxy.get('down', 0): # ä¸‹è¡Œå¸¦å®½
            params.append(f"down_mbps={proxy['down']}")
        if proxy.get('alpn'):
            params.append(f"alpn={urllib.parse.quote(','.join(proxy['alpn']))}")
        if proxy.get('obfs'): # æ··æ·†æ–¹å¼
            params.append(f"obfs={proxy['obfs']}")
            if proxy.get('obfs-password'):
                params.append(f"obfsParam={urllib.parse.quote(proxy['obfs-password'])}")

        params_str = '&'.join(params) if params else ''
        return f"hysteria2://{password}@{server}:{port}{'?' + params_str if params_str else ''}#{name}"
        
    logger.debug(f"ä¸æ”¯æŒçš„ä»£ç†ç±»å‹æˆ–æ— æ³•è½¬æ¢çš„ä»£ç†: {proxy_type} - {proxy}")
    return None

def parse_url_to_clash_proxy(url: str) -> Optional[Dict]:
    """
    å°†æ ‡å‡†è®¢é˜… URL è§£æå› Clash ä»£ç†é…ç½®å­—å…¸ã€‚
    è¿™æ˜¯ convert_clash_proxy_to_url çš„é€†å‘æ“ä½œï¼Œç”¨äºç”Ÿæˆå®Œæ•´çš„ Clash YAMLã€‚
    """
    try:
        if url.startswith('ss://'):
            # SS é“¾æ¥æ ¼å¼: ss://auth@server:port[?params]#name
            match = re.match(r'ss://([^@]+)@([^:]+):(\d+)(?:\?([^#]+))?(?:#(.+))?', url)
            if not match: return None
            auth_b64, server, port, query_str, name = match.groups()
            
            auth_decoded = decode_base64(auth_b64)
            if ':' not in auth_decoded: return None # è®¤è¯ä¿¡æ¯ä¸æ­£ç¡®
            cipher, password = auth_decoded.split(':', 1) # åªåˆ†å‰²ä¸€æ¬¡

            proxy = {
                'type': 'ss',
                'name': urllib.parse.unquote(name or f"ss_{server}_{port}"),
                'server': server,
                'port': int(port),
                'cipher': cipher,
                'password': password,
                'udp': True # Clash SS é»˜è®¤ UDP æ”¯æŒ
            }
            # è§£ææŸ¥è¯¢å‚æ•°ä»¥è·å–æ’ä»¶ä¿¡æ¯
            if query_str:
                params = urllib.parse.parse_qs(query_str)
                plugin_type = params.get('plugin', [None])[0]
                if plugin_type == 'obfs':
                    proxy['plugin'] = 'obfs'
                    proxy['plugin-opts'] = {
                        'mode': params.get('obfs-mode', ['http'])[0],
                        'host': urllib.parse.unquote(params.get('obfs-host', [''])[0])
                    }
                elif plugin_type == 'v2ray-plugin':
                    proxy['plugin'] = 'v2ray-plugin'
                    plugin_opts = {
                        'mode': params.get('v2ray-plugin-mode', ['websocket'])[0],
                        'host': urllib.parse.unquote(params.get('v2ray-plugin-host', [''])[0]),
                        'path': urllib.parse.unquote(params.get('v2ray-plugin-path', [''])[0]),
                    }
                    if params.get('v2ray-plugin-tls', ['false'])[0].lower() == 'true': plugin_opts['tls'] = True
                    if params.get('v2ray-plugin-skip-cert-verify', ['false'])[0].lower() == 'true': plugin_opts['skip-cert-verify'] = True
                    if params.get('v2ray-plugin-mux', ['false'])[0].lower() == 'true': plugin_opts['mux'] = True
                    proxy['plugin-opts'] = plugin_opts
            return proxy

        elif url.startswith('vmess://'):
            # VMess é“¾æ¥æ ¼å¼: vmess://base64_encoded_json
            config_b64 = url[8:]
            config_json = decode_base64(config_b64)
            if not config_json: return None
            
            config = json.loads(config_json)
            proxy = {
                'type': 'vmess',
                'name': config.get('ps', 'unnamed'),
                'server': config.get('add'),
                'port': int(config.get('port')),
                'uuid': config.get('id'),
                'alterId': config.get('aid', 0),
                'network': config.get('net', 'tcp'),
                'cipher': config.get('type', 'auto'), # VMess JSON çš„ type æœ‰æ—¶æ˜¯åŠ å¯†æ–¹å¼
                'tls': config.get('tls', 'none').lower() == 'tls',
                'udp': True # Clash VMess é»˜è®¤ UDP æ”¯æŒ
            }

            # TLS ç›¸å…³çš„é¢å¤–é…ç½®
            if proxy['tls']:
                if config.get('host'): proxy['servername'] = config['host'] # VMess host often maps to Clash servername
                if config.get('sni'): proxy['servername'] = config['sni'] # SNI might be separate
                if config.get('allowInsecure', 0) == 1: proxy['skip-cert-verify'] = True
                if config.get('alpn'): proxy['alpn'] = config['alpn'].split(',')
                if config.get('fp'): proxy['client-fingerprint'] = config['fp']

            # ç½‘ç»œä¼ è¾“æ–¹å¼ç‰¹å®šé…ç½®
            if proxy['network'] == 'ws':
                proxy['ws-opts'] = {
                    'path': config.get('path', '/'),
                    'headers': {'Host': config.get('host', '')}
                }
            elif proxy['network'] == 'grpc':
                proxy['grpc-opts'] = {
                    'grpc-service-name': config.get('serviceName', ''),
                    'mode': config.get('mode', '')
                }
            elif proxy['network'] == 'http':
                proxy['http-opts'] = {
                    'method': config.get('method', 'GET'),
                    'headers': {'Host': [config.get('host', '')]} # Clash http headers are lists
                }
            return proxy

        elif url.startswith('trojan://'):
            # Trojan é“¾æ¥æ ¼å¼: trojan://password@server:port[?params]#name
            match = re.match(r'trojan://([^@]+)@([^:]+):(\d+)(?:\?([^#]+))?(?:#(.+))?', url)
            if not match: return None
            password, server, port, query_str, name = match.groups()

            proxy = {
                'type': 'trojan',
                'name': urllib.parse.unquote(name or f"trojan_{server}_{port}"),
                'server': server,
                'port': int(port),
                'password': password,
                'tls': True, # Trojan é“¾æ¥é€šå¸¸éšå« TLS
                'udp': True # Clash Trojan é»˜è®¤ UDP æ”¯æŒ
            }
            if query_str:
                params = urllib.parse.parse_qs(query_str)
                if params.get('sni'): proxy['servername'] = urllib.parse.unquote(params['sni'][0])
                if params.get('alpn'): proxy['alpn'] = params['alpn'][0].split(',')
                if params.get('fp'): proxy['client-fingerprint'] = params['fp'][0]
                if params.get('allowInsecure', ['0'])[0] == '1': proxy['skip-cert-verify'] = True

                # ç½‘ç»œä¼ è¾“æ–¹å¼
                network_type = params.get('type', [None])[0]
                if network_type == 'ws':
                    proxy['network'] = 'ws'
                    proxy['ws-opts'] = {
                        'path': urllib.parse.unquote(params.get('path', ['/'])[0]),
                        'headers': {'host': urllib.parse.unquote(params.get('host', [''])[0])}
                    }
                elif network_type == 'grpc':
                    proxy['network'] = 'grpc'
                    proxy['grpc-opts'] = {
                        'grpc-service-name': urllib.parse.unquote(params.get('serviceName', [''])[0]),
                        'mode': urllib.parse.unquote(params.get('mode', [''])[0])
                    }
            return proxy

        elif url.startswith('vless://'):
            # VLESS é“¾æ¥æ ¼å¼: vless://uuid@server:port[?params]#name
            match = re.match(r'vless://([^@]+)@([^:]+):(\d+)(?:\?([^#]+))?(?:#(.+))?', url)
            if not match: return None
            uuid_val, server, port, query_str, name = match.groups()

            proxy = {
                'type': 'vless',
                'name': urllib.parse.unquote(name or f"vless_{server}_{port}"),
                'server': server,
                'port': int(port),
                'uuid': uuid_val,
                'udp': True # Clash VLESS é»˜è®¤ UDP æ”¯æŒ
            }
            if query_str:
                params = urllib.parse.parse_qs(query_str)
                # TLS & Security
                if params.get('security', ['none'])[0].lower() == 'tls': proxy['tls'] = True
                if params.get('sni'): proxy['servername'] = urllib.parse.unquote(params['sni'][0])
                if params.get('alpn'): proxy['alpn'] = params['alpn'][0].split(',')
                if params.get('fp'): proxy['client-fingerprint'] = params['fp'][0]
                if params.get('allowInsecure', ['0'])[0] == '1': proxy['skip-cert-verify'] = True
                if params.get('flow'): proxy['flow'] = params['flow'][0]

                # Network Type
                network_type = params.get('type', ['tcp'])[0]
                proxy['network'] = network_type

                if network_type == 'ws':
                    proxy['ws-opts'] = {
                        'path': urllib.parse.unquote(params.get('path', ['/'])[0]),
                        'headers': {'host': urllib.parse.unquote(params.get('host', [''])[0])}
                    }
                elif network_type == 'grpc':
                    proxy['grpc-opts'] = {
                        'grpc-service-name': urllib.parse.unquote(params.get('serviceName', [''])[0]),
                        'mode': urllib.parse.unquote(params.get('mode', [''])[0])
                    }
            return proxy
        
        elif url.startswith('hysteria2://'):
            # Hysteria2 é“¾æ¥æ ¼å¼: hysteria2://password@server:port[?params]#name
            match = re.match(r'hysteria2://([^@]+)@([^:]+):(\d+)(?:\?([^#]+))?(?:#(.+))?', url)
            if not match: return None
            password, server, port, query_str, name = match.groups()

            proxy = {
                'type': 'hysteria2',
                'name': urllib.parse.unquote(name or f"hysteria2_{server}_{port}"),
                'server': server,
                'port': int(port),
                'password': password,
                'udp': True # Hysteria2 é»˜è®¤ UDP æ”¯æŒ
            }
            if query_str:
                params = urllib.parse.parse_qs(query_str)
                if params.get('sni'): proxy['sni'] = urllib.parse.unquote(params['sni'][0])
                if params.get('insecure', ['0'])[0] == '1': proxy['skip-cert-verify'] = True
                if params.get('fastopen', ['0'])[0] == '1': proxy['fast-open'] = True
                if params.get('up_mbps'): proxy['up'] = int(params['up_mbps'][0])
                if params.get('down_mbps'): proxy['down'] = int(params['down_mbps'][0])
                if params.get('alpn'): proxy['alpn'] = params['alpn'][0].split(',')
                if params.get('obfs'): proxy['obfs'] = params['obfs'][0]
                if params.get('obfsParam'): proxy['obfs-password'] = urllib.parse.unquote(params['obfsParam'][0])
            return proxy

        # TODO: æ·»åŠ å…¶ä»–åè®®ï¼ˆå¦‚ WireGuard, Tuic ç­‰ï¼‰çš„é€†å‘è§£æé€»è¾‘
        
        logger.debug(f"ä¸æ”¯æŒçš„ URL åè®®æˆ–è§£æå¤±è´¥: {url}")
        return None
    except Exception as e:
        logger.debug(f"è§£æ URL {url} åˆ° Clash ä»£ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def extract_nodes(content: str) -> List[str]:
    """
    ä»å„ç§å†…å®¹æ ¼å¼ä¸­æå–ä»£ç†èŠ‚ç‚¹ã€‚
    æ­¤å‡½æ•°ä¼šå°è¯•æ‰€æœ‰å¯èƒ½çš„è§£æç­–ç•¥ï¼ˆç›´æ¥åŒ¹é…ã€HTML å±æ€§ã€YAMLã€Base64 è§£ç åå†…å®¹ï¼‰ï¼Œ
    å¹¶æ±‡æ€»æ‰€æœ‰æ‰¾åˆ°çš„æœ‰æ•ˆèŠ‚ç‚¹ URLã€‚
    """
    nodes_found = set() # ä½¿ç”¨ set è‡ªåŠ¨å»é‡

    # é¢„å¤„ç†å†…å®¹ï¼Œç»Ÿä¸€æ¢è¡Œç¬¦
    content = content.replace('\r\n', '\n').replace('\r', '\n')

    # --- ç­–ç•¥ 1: å°è¯•ä»å†…å®¹ä¸­ç›´æ¥åŒ¹é…æ ‡å‡†è®¢é˜…é“¾æ¥ ---
    # æ— è®ºå†…å®¹æ˜¯ä»€ä¹ˆæ ¼å¼ï¼Œåªè¦èƒ½ç›´æ¥åŒ¹é…åˆ°æ ‡å‡†é“¾æ¥å°±æå–
    for pattern in NODE_PATTERNS.values():
        matches = re.findall(pattern, content, re.MULTILINE)
        for node in matches:
            nodes_found.add(node)
    
    # --- ç­–ç•¥ 2: å°è¯•ä» HTML å±æ€§ä¸­æå–è®¢é˜…é“¾æ¥ (ä¾‹å¦‚ onclick å±æ€§) ---
    # æŸ¥æ‰¾è¢«å•å¼•å·æˆ–åŒå¼•å·åŒ…è£¹çš„ã€ç¬¦åˆä»»ä½•è®¢é˜…é“¾æ¥æ¨¡å¼çš„å­—ç¬¦ä¸²ã€‚
    # è¿™å¯ä»¥æ•è· <button onclick='copyToClipboard("trojan://...")'> è¿™æ ·çš„é“¾æ¥
    html_link_matches = re.findall(rf'["\']({COMBINED_REGEX_PATTERN})["\']', content)
    for link in html_link_matches:
        # å¯¹æå–åˆ°çš„é“¾æ¥å†æ¬¡è¿›è¡Œæœ‰æ•ˆæ€§éªŒè¯ï¼Œç¡®ä¿å®ƒç¡®å®æ˜¯ä¸€ä¸ªåè®®é“¾æ¥
        for pattern in NODE_PATTERNS.values():
            if re.match(pattern, link):
                nodes_found.add(link)
                break # æ‰¾åˆ°åŒ¹é…ï¼Œè·³åˆ°ä¸‹ä¸€ä¸ªæå–åˆ°çš„é“¾æ¥

    # --- ç­–ç•¥ 3: å°è¯• YAML è§£æ (ç”¨äº Clash é…ç½®æ–‡ä»¶) ---
    try:
        yaml_content = yaml.safe_load(content)
        if isinstance(yaml_content, dict) and 'proxies' in yaml_content:
            for proxy_dict in yaml_content['proxies']:
                url_node = convert_clash_proxy_to_url(proxy_dict)
                if url_node:
                    nodes_found.add(url_node)
        elif isinstance(yaml_content, list): # æœ‰äº›è®¢é˜…æ˜¯ç›´æ¥çš„ä»£ç†åˆ—è¡¨
            for item in yaml_content:
                if isinstance(item, dict) and 'type' in item: # å‡è®¾æ˜¯ä»£ç†å­—å…¸
                    url_node = convert_clash_proxy_to_url(item)
                    if url_node: nodes_found.add(url_node)
            
    except yaml.YAMLError:
        pass # ä¸æ˜¯ YAML æ ¼å¼ï¼Œç»§ç»­

    # --- ç­–ç•¥ 4: å°è¯• JSON è§£æ (ç”¨äº VMess æˆ–å…¶ä»– JSON æ ¼å¼çš„è®¢é˜…) ---
    try:
        json_content = json.loads(content)
        if isinstance(json_content, list): # å¯èƒ½æ˜¯ VMess åˆ—è¡¨
            for config_dict in json_content:
                if isinstance(config_dict, dict) and config_dict.get('v') == '2' and config_dict.get('id'):
                    # å°è¯•å°† VMess JSON ç›´æ¥è½¬ä¸º URL
                    url_node = convert_clash_proxy_to_url({'type': 'vmess', **config_dict})
                    if url_node:
                        nodes_found.add(url_node)
                # å¦‚æœæ˜¯å…¶ä»–åè®®çš„ JSON æ ¼å¼ï¼Œå¯èƒ½éœ€è¦æ›´å¤šåˆ¤æ–­
        elif isinstance(json_content, dict) and 'proxies' in json_content: # å¯èƒ½æ˜¯ Clash JSON
             for proxy_dict in json_content['proxies']:
                url_node = convert_clash_proxy_to_url(proxy_dict)
                if url_node: nodes_found.add(url_node)
    except json.JSONDecodeError:
        pass # ä¸æ˜¯ JSON æ ¼å¼ï¼Œç»§ç»­

    # --- ç­–ç•¥ 5: å°è¯• Base64 è§£ç ï¼Œç„¶åå†æ¬¡å°è¯•è§£æ ---
    decoded_content = decode_base64(content)
    if decoded_content and len(decoded_content) > 20:
        # å¯¹è§£ç åçš„å†…å®¹å†æ¬¡æ‰§è¡Œæ‰€æœ‰æå–ç­–ç•¥ (ä½†é¿å…æ— é™é€’å½’)
        # æå–ç›´é“¾
        for pattern in NODE_PATTERNS.values():
            matches = re.findall(pattern, decoded_content, re.MULTILINE)
            for node in matches:
                nodes_found.add(node)
        
        # å°è¯• YAML
        try:
            yaml_content_decoded = yaml.safe_load(decoded_content)
            if isinstance(yaml_content_decoded, dict) and 'proxies' in yaml_content_decoded:
                for proxy_dict in yaml_content_decoded['proxies']:
                    url_node = convert_clash_proxy_to_url(proxy_dict)
                    if url_node: nodes_found.add(url_node)
            elif isinstance(yaml_content_decoded, list):
                for item in yaml_content_decoded:
                    if isinstance(item, dict) and 'type' in item:
                        url_node = convert_clash_proxy_to_url(item)
                        if url_node: nodes_found.add(url_node)
        except yaml.YAMLError:
            pass
        
        # å°è¯• JSON
        try:
            json_content_decoded = json.loads(decoded_content)
            if isinstance(json_content_decoded, list):
                for config_dict in json_content_decoded:
                    if isinstance(config_dict, dict) and config_dict.get('v') == '2' and config_dict.get('id'):
                        url_node = convert_clash_proxy_to_url({'type': 'vmess', **config_dict})
                        if url_node: nodes_found.add(url_node)
            elif isinstance(json_content_decoded, dict) and 'proxies' in json_content_decoded:
                 for proxy_dict in json_content_decoded['proxies']:
                    url_node = convert_clash_proxy_to_url(proxy_dict)
                    if url_node: nodes_found.add(url_node)
        except json.JSONDecodeError:
            pass

    # æœ€ç»ˆè¿‡æ»¤ï¼šç¡®ä¿æ‰€æœ‰æå–åˆ°çš„éƒ½æ˜¯æœ‰æ•ˆçš„è®¢é˜… URLï¼Œå¹¶ä¸”é•¿åº¦åˆç†
    # è¿‡æ»¤æ‰ä¸€äº›å¯èƒ½æ˜¯ä»£ç ç‰‡æ®µæˆ–æ— æ•ˆçš„çŸ­å­—ç¬¦ä¸²
    final_filtered_nodes = []
    for node in nodes_found:
        is_valid_url_pattern = False
        for pattern in NODE_PATTERNS.values():
            if re.match(pattern, node):
                is_valid_url_pattern = True
                break
        
        if is_valid_url_pattern and len(node) > 20: # é•¿åº¦é™åˆ¶ï¼Œé¿å…è¯¯æŠ¥çŸ­å­—ç¬¦ä¸²
            final_filtered_nodes.append(node)
    
    # è¿”å›åˆ—è¡¨ï¼Œæ–¹ä¾¿åç»­æ’åº
    return final_filtered_nodes

async def fetch_with_retry(session: aiohttp.ClientSession, url: str, retries: int = 3, backoff_factor: float = 1.0) -> str:
    """å¸¦é‡è¯•æœºåˆ¶åœ°è·å– URL å†…å®¹ã€‚"""
    for attempt in range(retries):
        try:
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=args.timeout)) as response:
                response.raise_for_status() # å¯¹ 4xx/5xx å“åº”æŠ›å‡ºå¼‚å¸¸
                return await response.text()
        except aiohttp.ClientError as e:
            logger.debug(f"å°è¯• {attempt + 1}/{retries} å¤±è´¥ï¼ŒURL: {url}ï¼Œé”™è¯¯: {e}")
            if attempt < retries - 1:
                await asyncio.sleep(backoff_factor * (2 ** attempt)) # æŒ‡æ•°é€€é¿
    logger.error(f"åœ¨ {retries} æ¬¡å°è¯•åæœªèƒ½æˆåŠŸè·å– URL: {url}")
    return ""

async def fetch_url_nodes_task(session: aiohttp.ClientSession, url: str, semaphore: asyncio.Semaphore, url_node_counts: Dict, failed_urls: Set) -> List[str]:
    """ä»å•ä¸ª URL è·å–å¹¶æå–èŠ‚ç‚¹çš„å¼‚æ­¥ä»»åŠ¡ã€‚"""
    async with semaphore: # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
        logger.info(f"æ­£åœ¨å¤„ç† URL: {url}")
        try:
            content = await fetch_with_retry(session, url)
            if not content:
                failed_urls.add(url)
                url_node_counts[url] = 0
                logger.warning(f"æœªèƒ½è·å–å†…å®¹æˆ–å†…å®¹ä¸ºç©ºï¼ŒURL: {url}")
                return []
            
            nodes = extract_nodes(content)
            url_node_counts[url] = len(nodes)
            if nodes:
                logger.info(f"ä» {url} ä¸­æå–åˆ° {len(nodes)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹ã€‚")
            else:
                logger.info(f"ä» {url} ä¸­æœªæå–åˆ°æœ‰æ•ˆèŠ‚ç‚¹ã€‚")
            return nodes
        except Exception as e:
            logger.error(f"å¤„ç† URL {url} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            failed_urls.add(url)
            return []

async def process_urls(urls: List[str], max_concurrency: int) -> tuple[List[str], Dict, Set]:
    """å¹¶å‘å¤„ç†å¤šä¸ª URLã€‚"""
    semaphore = asyncio.Semaphore(max_concurrency)
    url_node_counts = defaultdict(int) # æ¯ä¸ª URL å¯¹åº”çš„èŠ‚ç‚¹æ•°é‡
    failed_urls = set() # è·å–å¤±è´¥çš„ URL é›†åˆ
    all_extracted_nodes = [] # å­˜å‚¨æ‰€æœ‰æå–åˆ°çš„èŠ‚ç‚¹ï¼ˆå¯èƒ½æœ‰é‡å¤ï¼‰
    
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url_nodes_task(session, url, semaphore, url_node_counts, failed_urls) for url in urls]
        # ä½¿ç”¨ return_exceptions=True ç¡®ä¿å³ä½¿æœ‰ä»»åŠ¡å¤±è´¥ï¼Œå…¶ä»–ä»»åŠ¡ä¹Ÿèƒ½ç»§ç»­
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for nodes_or_exception in results:
            if isinstance(nodes_or_exception, list): # æˆåŠŸè¿”å›èŠ‚ç‚¹åˆ—è¡¨
                all_extracted_nodes.extend(nodes_or_exception)
            else:
                # å¼‚å¸¸å·²åœ¨ fetch_url_nodes_task ä¸­å¤„ç†å’Œè®°å½•ï¼Œæ­¤å¤„è·³è¿‡
                pass 
                
    # å»é‡æ‰€æœ‰æå–åˆ°çš„èŠ‚ç‚¹
    unique_nodes = list(dict.fromkeys(all_extracted_nodes)) # Python 3.7+ ä¿æŒæ’å…¥é¡ºåºçš„å»é‡æ–¹æ³•
    return unique_nodes, url_node_counts, failed_urls

def generate_clash_config(nodes: List[str]) -> Dict:
    """
    æ ¹æ®æå–åˆ°çš„èŠ‚ç‚¹ URL ç”Ÿæˆ Clash YAML é…ç½®ã€‚
    æ­¤å‡½æ•°ä¼šå°è¯•å°†æ‰€æœ‰æ”¯æŒçš„ URL åè®®é€†å‘è§£æä¸º Clash å­—å…¸æ ¼å¼ã€‚
    """
    proxies_clash_format = []
    for node_url in nodes:
        clash_proxy = parse_url_to_clash_proxy(node_url)
        if clash_proxy:
            proxies_clash_format.append(clash_proxy)
        else:
            logger.debug(f"æœªèƒ½å°†èŠ‚ç‚¹ URL è½¬æ¢ä¸º Clash ä»£ç†æ ¼å¼: {node_url}")
            
    # Clash é…ç½®æ–‡ä»¶çš„åŸºæœ¬ç»“æ„
    clash_config = {
        'port': 7890,
        'socks-port': 7891,
        'redir-port': 7892,
        'mixed-port': 7893,
        'mode': 'rule',
        'log-level': 'info',
        'allow-lan': True,
        'bind-address': '*',
        'external-controller': '127.0.0.1:9090',
        'secret': '',
        'dns': {
            'enable': True,
            'ipv6': False,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'default-nameserver': [
                '114.114.114.114',
                '223.5.5.5',
                '8.8.8.8'
            ],
            'nameserver': [
                'https://dns.google/dns-query',
                'tls://dns.google'
            ],
            'fallback': [],
            'fallback-filter': {
                'geoip': True,
                'geoip-code': 'CN',
                'ipcidr': [
                    '240.0.0.0/4'
                ]
            }
        },
        'proxies': proxies_clash_format, # æ”¾ç½®è½¬æ¢åçš„ä»£ç†
        'proxy-groups': [
            {
                'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
                'type': 'select',
                'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'DIRECT'] + [p['name'] for p in proxies_clash_format if 'name' in p]
            },
            {
                'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©',
                'type': 'url-test',
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300,
                'proxies': [p['name'] for p in proxies_clash_format if 'name' in p]
            },
            {
                'name': 'DIRECT',
                'type': 'direct'
            }
        ],
        'rules': [
            'GEOIP,CN,DIRECT',
            'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©'
        ]
    }
    return clash_config

def main():
    """ä¸»å‡½æ•°ï¼Œè´Ÿè´£ç¨‹åºçš„æ•´ä½“æµç¨‹ã€‚"""
    global args # å°† args è®¾ç½®ä¸ºå…¨å±€å˜é‡ï¼Œä»¥ä¾¿åœ¨å¼‚æ­¥å‡½æ•°ä¸­è®¿é—®
    args = setup_argparse()
    
    # è¯»å– URL åˆ—è¡¨
    try:
        with open(args.sources, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except FileNotFoundError:
        logger.error(f"æºæ–‡ä»¶ {args.sources} æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ã€‚")
        return
    
    # å¤„ç† URL å¹¶æå–èŠ‚ç‚¹
    start_time = datetime.now()
    logger.info(f"å¼€å§‹å¤„ç† {len(urls)} ä¸ª URL...")
    
    # è¿è¡Œå¼‚æ­¥ä¸»æµç¨‹
    unique_nodes, url_node_counts, failed_urls = asyncio.run(process_urls(urls, args.max_concurrency))
    
    # å¯¹æå–åˆ°çš„èŠ‚ç‚¹è¿›è¡Œæ’åº
    unique_nodes.sort()
    
    # --- ç”Ÿæˆå¹¶æ‰“å°æŠ¥å‘Š ---
    total_nodes_extracted = len(unique_nodes)
    report_lines = [
        f"å¤„ç†å®Œæˆï¼Œè€—æ—¶ {(datetime.now() - start_time).total_seconds():.2f} ç§’",
        f"æ€»å…±æå–åˆ° {total_nodes_extracted} ä¸ªå”¯ä¸€èŠ‚ç‚¹ã€‚",
        "\næ¯ä¸ª URL çš„èŠ‚ç‚¹æå–æ•°é‡:"
    ]
    # æ ¼å¼åŒ–è¡¨æ ¼å¤´éƒ¨
    report_lines.append("{:<70} {:<15} {:<10}".format("URL", "æ‰¾åˆ°çš„èŠ‚ç‚¹æ•°", "çŠ¶æ€"))
    report_lines.append("-" * 95)
    
    # æŒ‰æ‰¾åˆ°çš„èŠ‚ç‚¹æ•°é™åºæ’åºï¼Œå¹¶æ·»åŠ åˆ°æŠ¥å‘Š
    sorted_url_counts = sorted(url_node_counts.items(), key=lambda x: x[1], reverse=True)
    for url, count in sorted_url_counts:
        status = "æˆåŠŸ" if count > 0 else "æ— èŠ‚ç‚¹"
        report_lines.append(f"{url:<70} {count:<15} {status:<10}")
    
    if failed_urls:
        report_lines.append("\nè·å–å¤±è´¥çš„ URL:")
        report_lines.extend(sorted(list(failed_urls))) # å¯¹å¤±è´¥çš„ URL ä¹Ÿè¿›è¡Œæ’åº
    
    # å°†æŠ¥å‘Šæ‰“å°åˆ°æ§åˆ¶å°
    for line in report_lines:
        logger.info(line)
    
    # --- ä¿å­˜èŠ‚ç‚¹åˆ°æ–‡ä»¶ ---
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    try:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write('\n'.join(unique_nodes))
        logger.info(f"å·²å°† {total_nodes_extracted} ä¸ªèŠ‚ç‚¹ä¿å­˜åˆ° {args.output}")
    except Exception as e:
        logger.error(f"ä¿å­˜èŠ‚ç‚¹åˆ° {args.output} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    # --- ä¿å­˜ Clash é…ç½®åˆ°æ–‡ä»¶ ---
    # ç¡®ä¿ Clash è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(args.clash_output), exist_ok=True)
    clash_config = generate_clash_config(unique_nodes)
    try:
        with open(args.clash_output, 'w', encoding='utf-8') as f:
            yaml.safe_dump(clash_config, f, allow_unicode=True, indent=2, sort_keys=False) # ä¿æŒé¡ºåºï¼Œç¾åŒ–è¾“å‡º
        logger.info(f"å·²å°† Clash é…ç½®ä¿å­˜åˆ° {args.clash_output}")
    except Exception as e:
        logger.error(f"ä¿å­˜ Clash é…ç½®åˆ° {args.clash_output} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == '__main__':
    main()
